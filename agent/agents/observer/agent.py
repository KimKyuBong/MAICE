"""
í•™ìŠµ ê´€ì°° ì—ì´ì „íŠ¸ - ìƒˆë¡œìš´ 3ê°œ ì±„ë„ êµ¬ì¡° ì‚¬ìš©
"""

import logging
import json
import asyncio
from typing import Dict, Any
from datetime import datetime
from agents.base_agent import BaseAgent, Task
from agents.common.prompt_utils import (
    sanitize_text,
    validate_prompt_content,
    format_prompt_with_variables
)
from agents.common.config_loader import PromptConfigLoader
from agents.common.event_bus import (
    publish_event,
    subscribe_and_listen,
    BACKEND_TO_AGENT,
    AGENT_TO_BACKEND,
    AGENT_STATUS,
    AGENT_TO_AGENT,
    MessageType
)
from utils.redis_streams_client import AgentRedisStreamsClient
from agents.common.llm_tool import SpecializedLLMTool, PromptTemplate, LLMConfig

logger = logging.getLogger(__name__)

class ObserverAgent(BaseAgent):
    """í•™ìŠµ ê´€ì°° ë° ë¶„ì„ ì—ì´ì „íŠ¸ - ìƒˆë¡œìš´ ì±„ë„ êµ¬ì¡°"""
    
    def __init__(self):
        super().__init__(name="ObserverAgent", role="observer")  # BaseAgent ì´ˆê¸°í™” (logger í¬í•¨)
        
        # Redis Streams í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.streams_client = AgentRedisStreamsClient("ObserverAgent")
        
        # í”„ë¡¬í”„íŠ¸ ì„¤ì • ë¡œë” ì´ˆê¸°í™”
        self.config_loader = PromptConfigLoader()
        self.prompt_config = self.config_loader.get_agent_config("observer")
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = self._build_system_prompt()
        
        # LLM íˆ´ ì´ˆê¸°í™”
        self.llm_tool = SpecializedLLMTool.create_observer_tool()
        
        super().__init__(
            name="Observer",
            role="í•™ìŠµ ê´€ì°° ë° ë¶„ì„",
            system_prompt=system_prompt,
            tools=[self.llm_tool]  # LLM íˆ´ ì¶”ê°€
        )
        
        self.observation_sessions = {}
    
    def _build_system_prompt(self) -> str:
        """ì„¤ì • íŒŒì¼ì—ì„œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        base_config = self.prompt_config.get("observer", {}).get("system_prompts", {}).get("base", "")
        
        if not base_config:
            return "ë‹¹ì‹ ì€ MAICEì˜ í•™ìŠµ ê³¼ì • ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•™ìƒì˜ ì§ˆë¬¸, ëª…ë£Œí™” ê³¼ì •, ë‹µë³€ì„ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•˜ì—¬ ë°±ì—”ë“œ ì‹œìŠ¤í…œì—ì„œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ êµ¬ì¡°í™”ëœ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
        
        return base_config
    
    async def initialize(self):
        """ì—ì´ì „íŠ¸ ì´ˆê¸°í™”"""
        await super().initialize()
        await self.streams_client.initialize()
    
    async def cleanup(self):
        """ì—ì´ì „íŠ¸ ì •ë¦¬"""
        await self.streams_client.close()
        await super().cleanup()
    
    async def run_subscriber(self):
        """Streamsì™€ pub/sub ê¸°ë°˜ ë©”ì‹œì§€ ìˆ˜ì‹ """
        self.logger.info("ğŸš€ ObserverAgent Streams + pub/sub êµ¬ë… ì‹œì‘")
        
        # pub/sub êµ¬ë… ì‹œì‘ (ë³„ë„ íƒœìŠ¤í¬ë¡œ ì‹¤í–‰)
        pubsub_task = asyncio.create_task(self.run_pubsub_subscriber())
        
        try:
            while True:
                try:
                    # Streamsì—ì„œ ë©”ì‹œì§€ ìˆ˜ì‹  - ëŒ€ìš©ëŸ‰ ë™ì‹œ ì²˜ë¦¬ (ìµœëŒ€ 50ê°œ)
                    messages = await self.streams_client.read_from_backend_stream(count=50, block=1000)
                    
                    if messages:
                        # ë™ì‹œ ì²˜ë¦¬í•  ë©”ì‹œì§€ë“¤ ë¶„ë¥˜
                        tasks = []
                        for msg_id, fields in messages:
                            self.logger.info(f"ğŸ“¥ Streamsì—ì„œ ë©”ì‹œì§€ ìˆ˜ì‹ : {msg_id}")
                            
                            # ë©”ì‹œì§€ íŒŒì‹± (ì´ë¯¸ decodeëœ ë¬¸ìì—´)
                            message_type = fields.get('type', '')
                            target_agent = fields.get('target_agent', '')
                            
                            self.logger.info(f"ğŸ” ë©”ì‹œì§€ ë¶„ì„: type={message_type}, target_agent={target_agent}")
                            
                            # msg_idê°€ bytesì¸ ê²½ìš°ì—ë§Œ decode, ì´ë¯¸ ë¬¸ìì—´ì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                            msg_id_str = msg_id.decode() if isinstance(msg_id, bytes) else str(msg_id)
                            
                            # ìê¸° ì—ì´ì „íŠ¸ë¡œ ì˜¨ ë©”ì‹œì§€ê°€ ì•„ë‹ˆë©´ ACKí•˜ê³  ê±´ë„ˆë›°ê¸°
                            if target_agent not in ["ObserverAgent", "Observer"]:
                                tasks.append(self.streams_client.ack_stream_message(msg_id_str))
                                continue
                            
                            # ë©”ì‹œì§€ ì²˜ë¦¬ íƒœìŠ¤í¬ ìƒì„±
                            if message_type == "observe_learning":
                                tasks.append(self._handle_learning_observation_stream(fields, msg_id_str))
                            elif message_type == "generate_summary":
                                tasks.append(self._handle_summary_generation_stream(fields, msg_id_str))
                            else:
                                self.logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì‹œì§€ íƒ€ì…: {message_type}")
                                tasks.append(self.streams_client.ack_stream_message(msg_id_str))
                        
                        # ëª¨ë“  ë©”ì‹œì§€ ë™ì‹œ ì²˜ë¦¬
                        if tasks:
                            await asyncio.gather(*tasks, return_exceptions=True)
                    
                    await asyncio.sleep(0.1)
                    
                except Exception as e:
                    self.logger.error(f"Streams ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                    await asyncio.sleep(0.1)
        
        finally:
            # pub/sub íƒœìŠ¤í¬ ì •ë¦¬
            pubsub_task.cancel()
            try:
                await pubsub_task
            except asyncio.CancelledError:
                pass
    
    async def run_pubsub_subscriber(self):
        """pub/sub ê¸°ë°˜ ë©”ì‹œì§€ ìˆ˜ì‹  (ObserverAgent ì „ìš©)"""
        self.logger.info("ğŸš€ ObserverAgent pub/sub êµ¬ë… ì‹œì‘")
        
        async def message_handler(channel: str, payload: Dict[str, Any]):
            try:
                target_agent = payload.get("target_agent")
                message_type = payload.get("type")
                
                # ìê¸° ì—ì´ì „íŠ¸ë¡œ ì˜¨ ë©”ì‹œì§€ê°€ ì•„ë‹ˆë©´ ì¦‰ì‹œ ë¦¬í„´
                if target_agent not in ["ObserverAgent", "Observer"]:
                    return
                
                self.logger.info(f"ğŸ“¥ pub/sub ë©”ì‹œì§€ ìˆ˜ì‹ : channel={channel}, target_agent={target_agent}, type={message_type}")
                
                if message_type == "generate_summary":
                    await self.process_summary_generation_request(payload)
                else:
                    self.logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” pub/sub ë©”ì‹œì§€ íƒ€ì…: {message_type}")
                    
            except Exception as e:
                self.logger.error(f"pub/sub ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        
        # AGENT_TO_AGENT ì±„ë„ êµ¬ë…
        await subscribe_and_listen([AGENT_TO_AGENT], message_handler, self)
        self.logger.info("âœ… ObserverAgent pub/sub ë©”ì‹œì§€ êµ¬ë… ì‹œì‘")
    
    async def _handle_learning_observation_stream(self, fields: Dict[str, Any], msg_id: str):
        """Streamsì—ì„œ ë°›ì€ í•™ìŠµ ê´€ì°° ìš”ì²­ ì²˜ë¦¬"""
        try:
            request_id = fields.get('request_id', '')
            session_id = int(fields.get('session_id', '0'))
            question = fields.get('question', '')
            answer = fields.get('answer', '')
            context_data = fields.get('context', '{}')
            
            try:
                context = json.loads(context_data) if context_data else {}
            except json.JSONDecodeError:
                context = {}
            
            self.logger.info(f"ğŸ”„ Streams í•™ìŠµ ê´€ì°° ìš”ì²­: ì„¸ì…˜ {session_id}")
            
            # í•™ìŠµ ê´€ì°° ìˆ˜í–‰
            observation_result = await self._observe_learning(question, answer, session_id, context)
            
            if observation_result.get("success"):
                await self._handle_successful_observation_stream(session_id, observation_result, request_id)
            else:
                await self._handle_observation_error_stream(session_id, observation_result, request_id)
            
            # ë©”ì‹œì§€ ACK
            await self.streams_client.ack_stream_message(msg_id)
            
        except Exception as e:
            self.logger.error(f"âŒ Streams í•™ìŠµ ê´€ì°° ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            await self.streams_client.ack_stream_message(msg_id)
    
    async def _handle_summary_generation_stream(self, fields: Dict[str, Any], msg_id: str):
        """Streamsì—ì„œ ë°›ì€ ìš”ì•½ ìƒì„± ìš”ì²­ ì²˜ë¦¬"""
        try:
            request_id = fields.get('request_id', '')
            session_id = int(fields.get('session_id', '0'))
            conversation_text = fields.get('conversation_text', '')
            
            self.logger.info(f"ğŸ”„ Streams ìš”ì•½ ìƒì„± ìš”ì²­: ì„¸ì…˜ {session_id}")
            
            # ìš”ì•½ ìƒì„± ìˆ˜í–‰
            summary_result = await self._generate_summary(conversation_text, session_id)
            
            if summary_result.get("success"):
                await self._handle_successful_summary_stream(session_id, summary_result, request_id)
            else:
                await self._handle_summary_error_stream(session_id, summary_result, request_id)
            
            # ë©”ì‹œì§€ ACK
            await self.streams_client.ack_stream_message(msg_id)
            
        except Exception as e:
            self.logger.error(f"âŒ Streams ìš”ì•½ ìƒì„± ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            await self.streams_client.ack_stream_message(msg_id)
    
    async def _handle_successful_observation_stream(self, session_id: int, result: Dict[str, Any], request_id: str):
        """Streamsë¡œ ì„±ê³µì ì¸ ê´€ì°° ê²°ê³¼ ì „ì†¡"""
        try:
            # Streamsë¡œ ê´€ì°° ê²°ê³¼ ì „ì†¡
            await self.streams_client.send_to_backend_stream({
                "type": MessageType.OBSERVATION_SUCCESS,
                "session_id": session_id,
                "result": result,
                "request_id": request_id
            })
            self.logger.info(f"âœ… Streamsë¡œ ê´€ì°° ê²°ê³¼ ì „ì†¡: ì„¸ì…˜ {session_id}")
            
        except Exception as e:
            self.logger.error(f"âŒ Streams ê´€ì°° ê²°ê³¼ ì „ì†¡ ì˜¤ë¥˜: {e}")
    
    async def _handle_observation_error_stream(self, session_id: int, result: Dict[str, Any], request_id: str):
        """Streamsë¡œ ê´€ì°° ì˜¤ë¥˜ ê²°ê³¼ ì „ì†¡"""
        try:
            error_message = result.get("error", "ê´€ì°° ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            # Streamsë¡œ ì—ëŸ¬ ê²°ê³¼ ì „ì†¡
            await self.streams_client.send_to_backend_stream({
                "type": MessageType.OBSERVATION_ERROR,
                "session_id": session_id,
                "error": error_message,
                "request_id": request_id
            })
            self.logger.info(f"âŒ Streamsë¡œ ê´€ì°° ì˜¤ë¥˜ ì „ì†¡: ì„¸ì…˜ {session_id}")
            
        except Exception as e:
            self.logger.error(f"âŒ Streams ê´€ì°° ì˜¤ë¥˜ ì „ì†¡ ì˜¤ë¥˜: {e}")
    
    async def _handle_successful_summary_stream(self, session_id: int, result: Dict[str, Any], request_id: str):
        """Streamsë¡œ ì„±ê³µì ì¸ ìš”ì•½ ê²°ê³¼ ì „ì†¡"""
        try:
            summary = result.get("summary", "")
            
            # Streamsë¡œ ìš”ì•½ ê²°ê³¼ ì „ì†¡
            await self.streams_client.send_to_backend_stream({
                "type": MessageType.SUMMARY_SUCCESS,
                "session_id": session_id,
                "summary": summary,
                "request_id": request_id
            })
            self.logger.info(f"âœ… Streamsë¡œ ìš”ì•½ ê²°ê³¼ ì „ì†¡: ì„¸ì…˜ {session_id}")
            
        except Exception as e:
            self.logger.error(f"âŒ Streams ìš”ì•½ ê²°ê³¼ ì „ì†¡ ì˜¤ë¥˜: {e}")
    
    async def _handle_summary_error_stream(self, session_id: int, result: Dict[str, Any], request_id: str):
        """Streamsë¡œ ìš”ì•½ ì˜¤ë¥˜ ê²°ê³¼ ì „ì†¡"""
        try:
            error_message = result.get("error", "ìš”ì•½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            # Streamsë¡œ ì—ëŸ¬ ê²°ê³¼ ì „ì†¡
            await self.streams_client.send_to_backend_stream({
                "type": MessageType.SUMMARY_ERROR,
                "session_id": session_id,
                "error": error_message,
                "request_id": request_id
            })
            self.logger.info(f"âŒ Streamsë¡œ ìš”ì•½ ì˜¤ë¥˜ ì „ì†¡: ì„¸ì…˜ {session_id}")
            
        except Exception as e:
            self.logger.error(f"âŒ Streams ìš”ì•½ ì˜¤ë¥˜ ì „ì†¡ ì˜¤ë¥˜: {e}")
    
    async def process_message(self, message_type: str, payload: Dict[str, Any]):
        """ë©”ì‹œì§€ ì²˜ë¦¬ (BaseAgent ë³‘ë ¬ ì²˜ë¦¬ìš©)"""
        try:
            if message_type in ["GENERATE_SUMMARY", "generate_summary"]:
                await self.process_summary_generation_request(payload)
            elif message_type in ["LEARNING_OBSERVATION", "learning_observation"]:
                await self.process_learning_observation_request(payload)
            else:
                self.logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì‹œì§€ íƒ€ì…: {message_type}")
        except Exception as e:
            self.logger.error(f"ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    
    async def process_task(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """BaseAgent ì¶”ìƒ ë©”ì„œë“œ êµ¬í˜„ - í•™ìŠµ ê´€ì°° íƒœìŠ¤í¬ ì²˜ë¦¬"""
        try:
            self.logger.info(f"í•™ìŠµ ê´€ì°° íƒœìŠ¤í¬ ì‹œì‘: {task_data.get('task_type', 'unknown')}")
            
            # íƒœìŠ¤í¬ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬
            task_type = task_data.get("task_type", "observe_learning")
            
            if task_type == "observe_learning":
                return await self._observe_learning(
                    question=task_data.get("question", ""),
                    answer=task_data.get("answer", ""),
                    session_id=task_data.get("session_id", ""),
                    context=task_data.get("context", {})
                )
            else:
                return {"success": False, "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íƒœìŠ¤í¬ íƒ€ì…: {task_type}"}
                
        except Exception as e:
            self.logger.error(f"íƒœìŠ¤í¬ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return {"success": False, "error": str(e)}
    
    async def process_learning_observation_request(self, payload: dict):
        """ë°±ì—”ë“œë¡œë¶€í„° ë°›ì€ í•™ìŠµ ê´€ì°° ìš”ì²­"""
        request_id = payload.get("request_id")
        session_id = payload.get("session_id")
        question = payload.get("question")
        answer = payload.get("answer")
        context = payload.get("context", {})
        
        try:
            # í•™ìŠµ ê´€ì°° ìˆ˜í–‰ (ê¸°ì¡´ íˆ´ ë¡œì§ì„ í•¨ìˆ˜ë¡œ ë³€í™˜)
            observation_result = await self._observe_learning(question, answer, session_id, context)
            
            if observation_result.get("success"):
                await self._handle_successful_observation(request_id, session_id, question, answer, observation_result)
            else:
                await self._handle_observation_error(request_id, session_id, question, answer, observation_result)
                
        except Exception as e:
            self.logger.error(f"í•™ìŠµ ê´€ì°° ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            await self._handle_observation_error(request_id, session_id, question, answer, str(e))
    
    async def process_summary_generation_request(self, payload: dict):
        """ë°±ì—”ë“œë¡œë¶€í„° ë°›ì€ ìš”ì•½ ìƒì„± ìš”ì²­"""
        request_id = payload.get("request_id")
        session_id = payload.get("session_id")
        conversation_text = payload.get("conversation_text")
        
        try:
            self.logger.info(f"ğŸ“ ìš”ì•½ ìƒì„± ìš”ì²­ ìˆ˜ì‹ : ì„¸ì…˜ {session_id}")
            
            # ìš”ì•½ ìƒì„± ìˆ˜í–‰
            summary_result = await self._generate_summary(conversation_text, session_id)
            
            if summary_result.get("success"):
                await self._handle_successful_summary(request_id, session_id, summary_result)
            else:
                await self._handle_summary_error(request_id, session_id, summary_result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"))
                
        except Exception as e:
            self.logger.error(f"ìš”ì•½ ìƒì„± ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            await self._handle_summary_error(request_id, session_id, str(e))
    
    async def _observe_learning(self, question: str, answer: str, session_id: str, context: dict) -> Dict[str, Any]:
        """í•™ìŠµ ê³¼ì • ìš”ì•½ - YAML í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ LLM ìš”ì•½ (ìµœì í™”ëœ ë¹„ë™ê¸° ì²˜ë¦¬)"""
        try:
            self.logger.info(f"í•™ìŠµ ê³¼ì • ìš”ì•½ ì‹œì‘: ì„¸ì…˜ {session_id}")
            
            # í•™ìŠµ ë§¥ë½ ì •ë³´ ì¶”ì¶œ (ë¹ ë¥¸ ì²˜ë¦¬)
            learning_context = self._extract_learning_context(context)
            
            # ê¸°ë³¸ ìš”ì•½ ìƒì„± (ë¹ ë¥¸ ì²˜ë¦¬)
            question_summary = self._summarize_question(question)
            clarification_summary = self._summarize_clarification(context)
            answer_summary = self._summarize_answer(answer)
            
            # ê¸°ë³¸ ìš”ì•½ ë°ì´í„° êµ¬ì„±
            summary_data = {
                "session_id": session_id,
                "timestamp": datetime.now().isoformat(),
                "question_summary": question_summary,
                "clarification_summary": clarification_summary,
                "answer_summary": answer_summary,
                "conversation_summary": answer_summary,
                "learning_context": learning_context,
                "title": question_summary[:50] + "...",  # ê¸°ë³¸ ì œëª©
                "summary": answer_summary,
                "key_concepts": [],
                "student_progress": "í•™ìŠµ ì§„í–‰ ì¤‘"
            }
            
            # ë°±ì—”ë“œë¡œ ì¦‰ì‹œ ì „ì†¡ (ê¸°ë³¸ ìš”ì•½)
            await self._send_summary_to_backend(summary_data)
            
            # LLM ìš”ì•½ì€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¹„ë™ê¸° ì²˜ë¦¬ (íƒ€ì„ì•„ì›ƒ ì—†ì´)
            asyncio.create_task(self._enhance_summary_with_llm_async(question, answer, session_id, summary_data))
            
            result = {
                "success": True,
                "session_id": session_id,
                "summary_sent": True,
                "timestamp": datetime.now().isoformat()
            }
            
            self.logger.info(f"í•™ìŠµ ê³¼ì • ìš”ì•½ ì™„ë£Œ: ì„¸ì…˜ {session_id}, ë°±ì—”ë“œ ì „ì†¡ ì™„ë£Œ")
            return result
            
        except Exception as e:
            self.logger.error(f"í•™ìŠµ ê³¼ì • ìš”ì•½ ì˜¤ë¥˜: {e}")
            return {"success": False, "error": str(e)}
    
    async def _enhance_summary_with_llm_async(self, question: str, answer: str, session_id: str, summary_data: dict):
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ LLMì„ ì‚¬ìš©í•œ ìš”ì•½ í–¥ìƒ (ë¹„ë™ê¸° ì²˜ë¦¬)"""
        try:
            self.logger.info(f"ğŸ”§ LLM ìš”ì•½ í–¥ìƒ ì‹œì‘: ì„¸ì…˜ {session_id}")
            
            # íƒ€ì„ì•„ì›ƒ ì„¤ì • (30ì´ˆ)
            enhanced_summary = await asyncio.wait_for(
                self._generate_summary_with_llm(f"í•™ìƒ ì§ˆë¬¸: {question}\n\nì—ì´ì „íŠ¸ ë‹µë³€: {answer}", session_id),
                timeout=30.0
            )
            
            # í–¥ìƒëœ ìš”ì•½ ë°ì´í„° ì—…ë°ì´íŠ¸
            enhanced_data = {
                **summary_data,
                "title": enhanced_summary.get("session_title", summary_data.get("title", "")),
                "summary": enhanced_summary.get("learning_summary", summary_data.get("summary", "")),
                "key_concepts": enhanced_summary.get("key_concepts", []),
                "student_progress": enhanced_summary.get("student_progress", summary_data.get("student_progress", "")),
                "enhanced": True,
                "enhanced_timestamp": datetime.now().isoformat()
            }
            
            # í–¥ìƒëœ ìš”ì•½ì„ ë°±ì—”ë“œë¡œ ì „ì†¡
            await self._send_summary_to_backend(enhanced_data)
            
            self.logger.info(f"âœ… LLM ìš”ì•½ í–¥ìƒ ì™„ë£Œ: ì„¸ì…˜ {session_id}")
            
        except asyncio.TimeoutError:
            self.logger.warning(f"â° LLM ìš”ì•½ í–¥ìƒ íƒ€ì„ì•„ì›ƒ: ì„¸ì…˜ {session_id} (30ì´ˆ ì´ˆê³¼)")
        except Exception as e:
            self.logger.error(f"âŒ LLM ìš”ì•½ í–¥ìƒ ì‹¤íŒ¨: ì„¸ì…˜ {session_id}, ì˜¤ë¥˜: {e}")
    
    def _summarize_question(self, question: str) -> str:
        """ì§ˆë¬¸ ìš”ì•½ - í•µì‹¬ ë‚´ìš©ë§Œ ì¶”ì¶œ"""
        try:
            if len(question) <= 100:
                return question
            
            # ê¸´ ì§ˆë¬¸ì€ ì•ë¶€ë¶„ê³¼ í•µì‹¬ í‚¤ì›Œë“œë¡œ ìš”ì•½
            words = question.split()
            if len(words) > 20:
                return f"{' '.join(words[:15])}... (ì´ {len(words)}ë‹¨ì–´)"
            
            return question
            
        except Exception as e:
            self.logger.error(f"ì§ˆë¬¸ ìš”ì•½ ì˜¤ë¥˜: {e}")
            return question[:100] + "..."
    
    def _summarize_clarification(self, context: dict) -> str:
        """ëª…ë£Œí™” ê³¼ì • ìš”ì•½ - ê¸°ë³¸ ì²˜ë¦¬"""
        try:
            clarification_turns = context.get("clarification_turns", [])
            if not clarification_turns:
                return "ëª…ë£Œí™” ê³¼ì • ì—†ìŒ"
            
            return f"ëª…ë£Œí™” {len(clarification_turns)}íšŒ ì§„í–‰"
            
        except Exception as e:
            self.logger.error(f"ëª…ë£Œí™” ìš”ì•½ ì˜¤ë¥˜: {e}")
            return "ëª…ë£Œí™” ê³¼ì • ìš”ì•½ ì‹¤íŒ¨"
    
    def _summarize_answer(self, answer: str) -> str:
        """ë‹µë³€ ìš”ì•½ - ê¸°ë³¸ ì²˜ë¦¬"""
        try:
            if len(answer) <= 200:
                return answer
            
            # ë‹µë³€ì˜ ì•ë¶€ë¶„ê³¼ í•µì‹¬ í‚¤ì›Œë“œë¡œ ìš”ì•½
            words = answer.split()
            if len(words) > 50:
                return f"{' '.join(words[:40])}... (ì´ {len(words)}ë‹¨ì–´)"
            
            return answer
            
        except Exception as e:
            self.logger.error(f"ë‹µë³€ ìš”ì•½ ì˜¤ë¥˜: {e}")
            return answer[:200] + "..." if len(answer) > 200 else answer
    
    def _summarize_clarification_process(self, context: dict) -> Dict[str, Any]:
        """ëª…ë£Œí™” ê³¼ì • ìš”ì•½"""
        try:
            clarification_info = context.get("clarification_responses", {})
            
            if not clarification_info:
                return {"has_clarification": False, "summary": "ëª…ë£Œí™” ê³¼ì • ì—†ìŒ"}
            
            # ëª…ë£Œí™” ì§ˆë¬¸ê³¼ ë‹µë³€ ìš”ì•½
            clarification_summary = []
            for key, value in clarification_info.items():
                if isinstance(value, str) and len(value) > 50:
                    summary = value[:50] + "..."
                else:
                    summary = str(value)
                clarification_summary.append(f"{key}: {summary}")
            
            return {
                "has_clarification": True,
                "total_clarifications": len(clarification_info),
                "summary": "; ".join(clarification_summary),
                "detailed_responses": clarification_info
            }
            
        except Exception as e:
            self.logger.error(f"ëª…ë£Œí™” ê³¼ì • ìš”ì•½ ì˜¤ë¥˜: {e}")
            return {"has_clarification": False, "summary": "ìš”ì•½ ì‹¤íŒ¨"}
    
    def _summarize_answer(self, answer: str) -> str:
        """ë‹µë³€ ìš”ì•½ - í•µì‹¬ ë‚´ìš©ë§Œ ì¶”ì¶œ"""
        try:
            # ê°„ë‹¨í•œ ìš”ì•½ (ì‹¤ì œë¡œëŠ” LLMì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ)
            if len(answer) <= 200:
                return answer
            
            # ê¸´ ë‹µë³€ì€ êµ¬ì¡°ë³„ë¡œ ìš”ì•½
            lines = answer.split('\n')
            summary_parts = []
            
            for line in lines:
                if line.strip() and len(line.strip()) > 10:
                    # ì œëª©ì´ë‚˜ ì¤‘ìš”í•œ ë‚´ìš©ë§Œ ì¶”ì¶œ
                    if line.startswith('##') or line.startswith('**'):
                        summary_parts.append(line.strip())
                    elif len(summary_parts) < 5:  # ìµœëŒ€ 5ê°œ ë¼ì¸ë§Œ
                        summary_parts.append(line.strip())
            
            if summary_parts:
                return "\n".join(summary_parts) + f"\n... (ì´ {len(answer)}ì)"
            
            return answer[:200] + "..."
            
        except Exception as e:
            self.logger.error(f"ë‹µë³€ ìš”ì•½ ì˜¤ë¥˜: {e}")
            return answer[:200] + "..." if len(answer) > 200 else answer
    
    def _extract_learning_context(self, context: dict) -> Dict[str, Any]:
        """í•™ìŠµ ë§¥ë½ ì •ë³´ ì¶”ì¶œ"""
        try:
            return {
                "unit": context.get("unit", ""),
                "learning_objective": context.get("learning_objective", ""),
                "knowledge_type": context.get("knowledge_type", ""),
                "difficulty": context.get("difficulty", ""),
                "student_id": context.get("student_id", "")
            }
        except Exception as e:
            self.logger.error(f"í•™ìŠµ ë§¥ë½ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return {}
    
    async def _send_summary_to_backend(self, summary_data: dict):
        """ìš”ì•½ëœ ì •ë³´ë¥¼ ë°±ì—”ë“œë¡œ ì „ì†¡ - ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹"""
        try:
            session_id = summary_data.get("session_id")
            
            # 1. ìš”ì•½ ì‹œì‘ ì•Œë¦¼
            await self.streams_client.send_to_backend_stream({
                "type": MessageType.SUMMARY_START,
                "session_id": session_id,
                "message": "í•™ìŠµ ê³¼ì •ì„ ë¶„ì„í•˜ê³  ìš”ì•½ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
                "timestamp": datetime.now().isoformat()
            })
            
            # 2. ìš”ì•½ ì§„í–‰ ìƒí™© ìŠ¤íŠ¸ë¦¬ë°
            await self.streams_client.send_to_backend_stream({
                "type": MessageType.SUMMARY_PROGRESS,
                "session_id": session_id,
                "message": "ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë¶„ì„í•˜ì—¬ í•™ìŠµ í¬ì¸íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤...",
                "progress": 60,
                "timestamp": datetime.now().isoformat()
            })
            
            # 3. ìµœì¢… ìš”ì•½ ì „ì†¡
            await self.streams_client.send_to_backend_stream({
                "type": MessageType.SUMMARY_COMPLETE,
                "session_id": session_id,
                "message": f"í•™ìŠµ ìš”ì•½ ì™„ë£Œ: {summary_data.get('summary_title', 'í•™ìŠµ ê³¼ì • ìš”ì•½')}",
                "data": summary_data,
                "timestamp": datetime.now().isoformat()
            })
            
            self.logger.info(f"âœ… ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ í•™ìŠµ ìš”ì•½ ë°±ì—”ë“œ ì „ì†¡ ì™„ë£Œ: ì„¸ì…˜ {session_id}")
            
        except Exception as e:
            self.logger.error(f"âŒ ë°±ì—”ë“œ ì „ì†¡ ì˜¤ë¥˜: {e}")
            raise
    
    async def _handle_successful_observation(self, request_id: str, session_id: str, question: str, answer: str, result: Dict[str, Any]):
        """ì„±ê³µì ì¸ ê´€ì°° ì²˜ë¦¬"""
        try:
            # Streamsë¡œ ì„±ê³µ ì‹ í˜¸ ì „ì†¡
            success_message = {
                "type": MessageType.OBSERVATION_SUCCESS,
                "request_id": request_id,
                "session_id": session_id,
                "result": result,
                "timestamp": datetime.now().isoformat()
            }
            
            await self.streams_client.send_to_backend_stream(success_message)
            
            self.logger.info(f"ê´€ì°° ì„±ê³µ ì²˜ë¦¬ ì™„ë£Œ: ì„¸ì…˜ {session_id}")
            
        except Exception as e:
            self.logger.error(f"ê´€ì°° ì„±ê³µ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    
    async def _handle_observation_error(self, request_id: str, session_id: str, error: str):
        """ê´€ì°° ì˜¤ë¥˜ ì²˜ë¦¬"""
        try:
            # Streamsë¡œ ì˜¤ë¥˜ ì‹ í˜¸ ì „ì†¡
            error_message = {
                "type": MessageType.OBSERVATION_ERROR,
                "request_id": request_id,
                "session_id": session_id,
                "error": error,
                "timestamp": datetime.now().isoformat()
            }
            
            await self.streams_client.send_to_backend_stream(error_message)
            
            self.logger.error(f"ê´€ì°° ì˜¤ë¥˜ ì²˜ë¦¬ ì™„ë£Œ: ì„¸ì…˜ {session_id}, ì˜¤ë¥˜: {error}")
            
        except Exception as e:
            self.logger.error(f"ê´€ì°° ì˜¤ë¥˜ ì²˜ë¦¬ ì¤‘ ì¶”ê°€ ì˜¤ë¥˜ ë°œìƒ: {e}")

    async def _summarize_question_with_llm(self, question: str, session_id: int = None) -> str:
        """LLMì„ í†µí•œ ì§ˆë¬¸ ìš”ì•½"""
        try:
            # YAMLì—ì„œ ì§ˆë¬¸ ìš”ì•½ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê°€ì ¸ì˜¤ê¸°
            template = self.prompt_config.get("observer", {}).get("system_prompts", {}).get("question_summary_template", "")
            if not template:
                self.logger.warning("YAMLì—ì„œ question_summary_templateì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ìš”ì•½ ì‚¬ìš©")
                return self._fallback_question_summary(question)
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = template.format(
                question=question,
                summary=""
            )
            
            # LLM í˜¸ì¶œ
            response = await self._call_llm_for_summary(prompt, "ì§ˆë¬¸ ìš”ì•½", session_id=None)
            
            # ì‘ë‹µ ê²€ì¦ ë° ê¸¸ì´ ì œí•œ
            max_length = self.prompt_config.get("observer", {}).get("summary_guidelines", {}).get("question_summary", {}).get("max_length", 100)
            if len(response) > max_length:
                response = response[:max_length] + "..."
            
            return response
            
        except Exception as e:
            self.logger.error(f"LLM ì§ˆë¬¸ ìš”ì•½ ì˜¤ë¥˜: {e}")
            return self._fallback_question_summary(question)
    
    async def _summarize_clarification_with_llm(self, context: dict, session_id: int = None) -> Dict[str, Any]:
        """LLMì„ í†µí•œ ëª…ë£Œí™” ê³¼ì • ìš”ì•½"""
        try:
            clarification_info = context.get("clarification_responses", {})
            
            if not clarification_info:
                return {"has_clarification": False, "summary": "ëª…ë£Œí™” ê³¼ì • ì—†ìŒ"}
            
            # YAMLì—ì„œ ëª…ë£Œí™” ìš”ì•½ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê°€ì ¸ì˜¤ê¸°
            template = self.prompt_config.get("observer", {}).get("system_prompts", {}).get("clarification_summary_template", "")
            if not template:
                self.logger.warning("YAMLì—ì„œ clarification_summary_templateì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ìš”ì•½ ì‚¬ìš©")
                return self._fallback_clarification_summary(context)
            
            # ëª…ë£Œí™” ë°ì´í„° ì¤€ë¹„
            clarification_data = self._format_clarification_data(clarification_info)
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = template.format(
                clarification_data=clarification_data,
                summary=""
            )
            
            # LLM í˜¸ì¶œ
            response = await self._call_llm_for_summary(prompt, "ëª…ë£Œí™” ê³¼ì • ìš”ì•½", session_id=None)
            
            return {
                "has_clarification": True,
                "total_clarifications": len(clarification_info),
                "summary": response,
                "detailed_responses": clarification_info
            }
            
        except Exception as e:
            self.logger.error(f"LLM ëª…ë£Œí™” ìš”ì•½ ì˜¤ë¥˜: {e}")
            return self._fallback_clarification_summary(context)
    
    async def _summarize_answer_with_llm(self, answer: str, session_id: int = None) -> str:
        """LLMì„ í†µí•œ ë‹µë³€ ìš”ì•½"""
        try:
            # YAMLì—ì„œ ë‹µë³€ ìš”ì•½ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê°€ì ¸ì˜¤ê¸°
            template = self.prompt_config.get("observer", {}).get("system_prompts", {}).get("answer_summary_template", "")
            if not template:
                self.logger.warning("YAMLì—ì„œ answer_summary_templateì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ìš”ì•½ ì‚¬ìš©")
                return await self._fallback_answer_summary(answer)
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = template.format(
                answer=answer,
                summary=""
            )
            
            # LLM í˜¸ì¶œ
            response = await self._call_llm_for_summary(prompt, "ë‹µë³€ ìš”ì•½", session_id=None)
            
            # ì‘ë‹µ ê²€ì¦ ë° ê¸¸ì´ ì œí•œ
            max_length = self.prompt_config.get("observer", {}).get("summary_guidelines", {}).get("answer_summary", {}).get("max_length", 200)
            if len(response) > max_length:
                response = response[:max_length] + "..."
            
            return response
            
        except Exception as e:
            self.logger.error(f"LLM ë‹µë³€ ìš”ì•½ ì˜¤ë¥˜: {e}")
            return await self._fallback_answer_summary(answer)
    
    async def _call_llm_for_summary(self, prompt: str, summary_type: str, session_id: int = None) -> str:
        """ìš”ì•½ì„ ìœ„í•œ LLM í˜¸ì¶œ - ìƒˆë¡œìš´ LLM íˆ´ ì‚¬ìš©"""
        try:
            # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt_dict = {
                "system": self._build_system_prompt(),
                "user": prompt
            }
            
            # LLM íˆ´ ì‹¤í–‰ (session_id ì „ë‹¬)
            result = await self.llm_tool.execute(
                prompt_dict,
                session_id=session_id
            )
            
            # LLM íˆ´ ì‘ë‹µ ì²˜ë¦¬ (ë”•ì…”ë„ˆë¦¬ í˜•íƒœ)
            if isinstance(result, dict) and result.get("success"):
                response = result.get("content", "")
            else:
                self.logger.error(f"LLM {summary_type} í˜¸ì¶œ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
                return ""
            
            self.logger.info(f"LLM {summary_type} ì‘ë‹µ: {response[:100]}...")
            return response
            
        except Exception as e:
            self.logger.error(f"LLM {summary_type} í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return ""
    
    def _format_clarification_data(self, clarification_info: dict) -> str:
        """ëª…ë£Œí™” ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ í¬ë§·íŒ…"""
        formatted_parts = []
        
        for key, value in clarification_info.items():
            if isinstance(value, str):
                formatted_parts.append(f"**{key}**: {value}")
            else:
                formatted_parts.append(f"**{key}**: {str(value)}")
        
        return "\n".join(formatted_parts)
    
    def _fallback_question_summary(self, question: str) -> str:
        """LLM ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì§ˆë¬¸ ìš”ì•½"""
        if len(question) <= 100:
            return question
        return question[:100] + "..."
    
    def _fallback_clarification_summary(self, context: dict) -> Dict[str, Any]:
        """LLM ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ëª…ë£Œí™” ìš”ì•½"""
        clarification_info = context.get("clarification_responses", {})
        if not clarification_info:
            return {"has_clarification": False, "summary": "ëª…ë£Œí™” ê³¼ì • ì—†ìŒ"}
        
        summary_parts = []
        for key, value in clarification_info.items():
            if isinstance(value, str) and len(value) > 50:
                summary = value[:50] + "..."
            else:
                summary = str(value)
            summary_parts.append(f"{key}: {summary}")
        
        return {
            "has_clarification": True,
            "total_clarifications": len(clarification_info),
            "summary": "; ".join(summary_parts),
            "detailed_responses": clarification_info
        }
    
    async def _fallback_answer_summary(self, answer: str, session_id: int = None) -> str:
        """LLM ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë‹µë³€ ìš”ì•½ - LLMì„ ì‚¬ìš©í•œ ê°„ë‹¨í•œ ìš”ì•½ ì‹œë„"""
        if len(answer) <= 200:
            return answer
        
        try:
            # ê°„ë‹¨í•œ LLM ìš”ì•½ ì‹œë„
            summary_prompt = f"""ë‹¤ìŒ ìˆ˜í•™ êµìœ¡ ë‹µë³€ì„ í•µì‹¬ ë‚´ìš© ìœ„ì£¼ë¡œ 200ì ì´ë‚´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:

## ë‹µë³€:
{answer}

## ìš”ì•½ ê¸°ì¤€:
- ì£¼ìš” ê°œë…ê³¼ ì„¤ëª… ì¤‘ì‹¬
- í•µì‹¬ ì˜ˆì‹œë‚˜ ë°©ë²•ë¡  í¬í•¨
- í•™ìŠµ í¬ì¸íŠ¸ì™€ ì¤‘ìš”ì‚¬í•­ ê°•ì¡°
- ê°„ê²°í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì •ë¦¬

## ìš”ì•½:"""

            response = await self._call_llm_for_summary(summary_prompt, "ë‹µë³€ ìš”ì•½ (fallback)", session_id=session_id)
            if response and len(response.strip()) > 0:
                return response.strip()[:200]
            else:
                # LLM ì‘ë‹µì´ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ë³¸ ì²˜ë¦¬
                return answer[:200] + "..."
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ Fallback ìš”ì•½ LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            # LLM ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì²˜ë¦¬
            return answer[:200] + "..."
    
    async def _generate_summary_with_llm(self, conversation_text: str, session_id: str) -> Dict[str, str]:
        """LLMì„ ì‚¬ìš©í•œ ëŒ€í™” ìš”ì•½ ë° ì œëª© ìƒì„±"""
        try:
            # YAMLì—ì„œ ìš”ì•½ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê°€ì ¸ì˜¤ê¸°
            template = self.prompt_config.get("observer", {}).get("system_prompts", {}).get("conversation_summary_template", "")
            if not template:
                self.logger.error("âŒ YAMLì—ì„œ conversation_summary_templateì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return {
                    "title": "",
                    "summary": "ìš”ì•½ í…œí”Œë¦¿ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "key_concepts": [],
                    "student_progress": ""
                }
            
            # self.logger.info(f"âœ… YAMLì—ì„œ conversation_summary_template ë¡œë“œ ì„±ê³µ")
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = template.format(conversation_text=conversation_text)
            
            # LLM í˜¸ì¶œ (session_id ì „ë‹¬)
            response = await self._call_llm_for_summary(prompt, "ëŒ€í™” ìš”ì•½ ë° ì œëª© ìƒì„±", session_id=session_id)
            self.logger.info(f"ğŸ” LLM ì‘ë‹µ ìˆ˜ì‹ : {response[:200]}..." if len(response) > 200 else f"ğŸ” LLM ì‘ë‹µ ìˆ˜ì‹ : {response}")
            
            # JSON ì‘ë‹µ íŒŒì‹±
            try:
                import re
                import json
                
                # JSON ë¸”ë¡ ì¶”ì¶œ (```json ... ``` í˜•íƒœ)
                json_match = re.search(r'```json\s*\n(.*?)\n```', response, re.DOTALL | re.IGNORECASE)
                if json_match:
                    json_str = json_match.group(1).strip()
                    json_data = json.loads(json_str)
                    # self.logger.info(f"âœ… JSON ë¸”ë¡ì—ì„œ íŒŒì‹± ì„±ê³µ")
                else:
                    # JSON ë¸”ë¡ì´ ì—†ìœ¼ë©´ ì¤‘ê´„í˜¸ë¡œ ê°ì‹¸ì§„ JSON ê°ì²´ ì°¾ê¸°
                    start_idx = response.find('{')
                    if start_idx != -1:
                        # ì¤‘ê´„í˜¸ ê°œìˆ˜ë¥¼ ì„¸ì–´ì„œ JSON ê°ì²´ ë ì°¾ê¸°
                        brace_count = 0
                        end_idx = start_idx
                        for i, char in enumerate(response[start_idx:], start_idx):
                            if char == '{':
                                brace_count += 1
                            elif char == '}':
                                brace_count -= 1
                                if brace_count == 0:
                                    end_idx = i + 1
                                    break
                        
                        json_str = response[start_idx:end_idx]
                        json_data = json.loads(json_str)
                        self.logger.info(f"âœ… ì‘ë‹µì—ì„œ JSON íŒŒì‹± ì„±ê³µ")
                    else:
                        raise ValueError("JSON í˜•ì‹ì˜ ì‘ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
                # JSON ë°ì´í„°ì—ì„œ ì •ë³´ ì¶”ì¶œ
                title = json_data.get("session_title", "").strip()
                summary = json_data.get("learning_summary", "").strip()
                key_concepts = json_data.get("key_concepts", [])
                progress = json_data.get("student_progress", "").strip()
                
                # ì œëª©ì—ì„œ ë¶ˆí•„ìš”í•œ ì ‘ë‘ì‚¬ ì œê±°
                if title and (title.startswith("ì„¸ì…˜") or title.startswith("í•™ìŠµ")):
                    title = re.sub(r'^ì„¸ì…˜\s*\d*\s*[ì˜ì˜]\s*í•™ìŠµ\s*ìš”ì•½\s*:\s*', '', title)
                
                # key_conceptsê°€ ë¬¸ìì—´ì¸ ê²½ìš° ë°°ì—´ë¡œ ë³€í™˜
                if isinstance(key_concepts, str):
                    concepts_list = re.split(r'[,ï¼Œ\n]', key_concepts)
                    key_concepts = [c.strip().strip('"\'') for c in concepts_list if c.strip()]
                
                self.logger.info(f"âœ… ìš”ì•½ ì •ë³´ ì¶”ì¶œ ì„±ê³µ - ì œëª©: {title}, ìš”ì•½ ê¸¸ì´: {len(summary)}")
                return {
                    "title": title[:50] if title else "",  # ìµœëŒ€ 50ì
                    "summary": summary,
                    "key_concepts": key_concepts if isinstance(key_concepts, list) else [],
                    "student_progress": progress
                }
                
            except (json.JSONDecodeError, ValueError) as parse_error:
                self.logger.error(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {parse_error}")
                self.logger.error(f"âŒ íŒŒì‹± ì‹¤íŒ¨í•œ ì‘ë‹µ: {response[:500]}")
                
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì²˜ë¦¬
                lines = conversation_text.split('\n')
                question_line = ""
                for line in lines:
                    if "í•™ìƒ ì§ˆë¬¸:" in line or "ì§ˆë¬¸:" in line:
                        question_line = line
                        break
                
                return {
                    "title": "",
                    "summary": f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {question_line[:100]}..." if question_line else "ìš”ì•½ ìƒì„± ì‹¤íŒ¨",
                    "key_concepts": [],
                    "student_progress": ""
                }
            
        except Exception as e:
            self.logger.error(f"LLM ëŒ€í™” ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                "title": "",
                "summary": "",
                "key_concepts": [],
                "student_progress": ""
            }
    
    async def _generate_summary(self, conversation_text: str, session_id: str) -> Dict[str, Any]:
        """LLMì„ ì‚¬ìš©í•œ ëŒ€í™” ìš”ì•½ ìƒì„±"""
        try:
            # self.logger.info(f"ğŸ“ LLM ê¸°ë°˜ ëŒ€í™” ìš”ì•½ ìƒì„± ì‹œì‘: ì„¸ì…˜ {session_id}")
            
            # LLMì„ ì‚¬ìš©í•œ ìš”ì•½ ë° ì œëª© ìƒì„±
            summary_data = await self._generate_summary_with_llm(conversation_text, session_id)
            
            if not summary_data.get("summary"):
                # LLM ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ìš”ì•½ ìƒì„±
                summary_data = {
                    "title": "ìˆ˜í•™ í•™ìŠµ",
                    "summary": f"ì„¸ì…˜ {session_id}ì˜ í•™ìŠµ ìš”ì•½: {conversation_text[:200]}...",
                    "key_concepts": [],
                    "student_progress": ""
                }
                self.logger.warning(f"âš ï¸ LLM ìš”ì•½ ì‹¤íŒ¨, ê¸°ë³¸ ìš”ì•½ ì‚¬ìš©: ì„¸ì…˜ {session_id}")
            
            return {
                "success": True,
                "summary": summary_data.get("summary", ""),
                "title": summary_data.get("title", ""),
                "key_concepts": summary_data.get("key_concepts", []),
                "student_progress": summary_data.get("student_progress", ""),
                "session_id": session_id,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _handle_successful_summary(self, request_id: str, session_id: str, result: Dict[str, Any]):
        """ì„±ê³µì ì¸ ìš”ì•½ ì²˜ë¦¬"""
        try:
            summary_content = result.get('summary', '')
            
            # Streamsë¡œ ì„±ê³µ ì‹ í˜¸ ì „ì†¡
            success_message = {
                "type": MessageType.SUMMARY_COMPLETE,
                "request_id": request_id,
                "session_id": session_id,
                "summary": summary_content,
                "data": result,
                "timestamp": datetime.now().isoformat()
            }
            
            self.logger.info(f"ğŸ“¤ ë°±ì—”ë“œì— ìš”ì•½ ì „ì†¡: ì„¸ì…˜ {session_id}, request_id={request_id}, ìš”ì•½ê¸¸ì´={len(summary_content)}")
            self.logger.info(f"ğŸ“¤ ìš”ì•½ ë‚´ìš©: {summary_content[:100]}...")
            
            await self.streams_client.send_to_backend_stream(success_message)
            
            self.logger.info(f"âœ… ìš”ì•½ ì„±ê³µ ì²˜ë¦¬ ì™„ë£Œ: ì„¸ì…˜ {session_id}")
            
        except Exception as e:
            self.logger.error(f"âŒ ìš”ì•½ ì„±ê³µ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    
    async def _handle_summary_error(self, request_id: str, session_id: str, error: str):
        """ìš”ì•½ ì˜¤ë¥˜ ì²˜ë¦¬"""
        try:
            # Streamsë¡œ ì˜¤ë¥˜ ì‹ í˜¸ ì „ì†¡
            error_message = {
                "type": MessageType.SUMMARY_ERROR,
                "request_id": request_id,
                "session_id": session_id,
                "error": error,
                "timestamp": datetime.now().isoformat()
            }
            
            await self.streams_client.send_to_backend_stream(error_message)
            
            self.logger.error(f"ìš”ì•½ ì˜¤ë¥˜ ì²˜ë¦¬ ì™„ë£Œ: ì„¸ì…˜ {session_id} - {error}")
            
        except Exception as e:
            self.logger.error(f"ìš”ì•½ ì˜¤ë¥˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

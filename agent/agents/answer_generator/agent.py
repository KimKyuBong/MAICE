"""
ë‹µë³€ ìƒì„± ì „ë¬¸ ì—ì´ì „íŠ¸ - ìƒˆë¡œìš´ 3ê°œ ì±„ë„ êµ¬ì¡° ì‚¬ìš©
"""

import logging
import json
import asyncio
from typing import Dict, Any
from datetime import datetime
from agents.base_agent import BaseAgent, Task
from agents.common.prompt_utils import (
    sanitize_text,
    validate_prompt_content,
    format_prompt_with_variables,
    extract_json_from_response
)
from agents.common.config_loader import PromptConfigLoader
from agents.common.prompt_builder import PromptBuilder
from agents.common.constants import AnswerabilityType
from agents.common.event_bus import (
    publish_event,
    subscribe_and_listen,
    AGENT_TO_AGENT,
    MessageType
)
from utils.redis_streams_client import AgentRedisStreamsClient
from agents.common.llm_tool import SpecializedLLMTool, LLMConfig

logger = logging.getLogger(__name__)

class AnswerGeneratorAgent(BaseAgent):
    """ìˆ˜í•™ êµìœ¡ ë‹µë³€ ìƒì„± ì „ë¬¸ ì—ì´ì „íŠ¸ - ìƒˆë¡œìš´ ì±„ë„ êµ¬ì¡°"""
    
    def __init__(self):
        super().__init__(name="AnswerGeneratorAgent", role="answer_generator")  # BaseAgent ì´ˆê¸°í™” (logger í¬í•¨)
        
        # Redis Streams í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.streams_client = AgentRedisStreamsClient("AnswerGeneratorAgent")
        
        # í”„ë¡¬í”„íŠ¸ ì„¤ì • ë¡œë” ì´ˆê¸°í™”
        self.config_loader = PromptConfigLoader()
        
        # AnswerGenerator ì—ì´ì „íŠ¸ ì„¤ì • ë¡œë“œ
        yaml_data = self.config_loader.get_agent_config("answer_generator")
        if not yaml_data:
            self.logger.error("AnswerGenerator ì„¤ì •ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            raise RuntimeError("AnswerGenerator ì„¤ì • ë¡œë“œ ì‹¤íŒ¨")
        
        # í”„ë¡¬í”„íŠ¸ ë¹Œë” ì´ˆê¸°í™”
        self.prompt_builder = PromptBuilder(yaml_data)
        
        # YAML ë°ì´í„°ë¥¼ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ì €ì¥
        self.prompt_config = yaml_data
        
        if yaml_data and "templates" in yaml_data:
            self.logger.info(f"ğŸ” templates ì§ì ‘ ì ‘ê·¼ ê°€ëŠ¥: {list(yaml_data['templates'].keys())}")
        elif yaml_data and "answer_generator" in yaml_data:
            answer_gen_config = yaml_data["answer_generator"]
            self.logger.info(f"ğŸ” answer_generator í‚¤: {list(answer_gen_config.keys())}")
            if "templates" in answer_gen_config:
                self.logger.info(f"ğŸ” templates í‚¤: {list(answer_gen_config['templates'].keys())}")
            else:
                self.logger.warning(f"âš ï¸ answer_generator ì•ˆì— templates í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤!")
        else:
            self.logger.warning(f"âš ï¸ templatesë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        
        # LLM íˆ´ ì´ˆê¸°í™”
        self.llm_tool = SpecializedLLMTool.create_answer_generator_tool()
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ëŠ” PromptBuilderë¥¼ í†µí•´ ë™ì ìœ¼ë¡œ ìƒì„±
        
        # íˆ´ ì œê±° - í•¨ìˆ˜ë¡œ ëŒ€ì²´
        super().__init__(
            name="AnswerGenerator",
            role="ìˆ˜í•™ êµìœ¡ ë‹µë³€ ìƒì„±",
            system_prompt="",  # PromptBuilderë¥¼ í†µí•´ ë™ì ìœ¼ë¡œ ìƒì„±
            tools=[]  # íˆ´ ì—†ìŒ
        )
    
    
    async def initialize(self):
        """ì—ì´ì „íŠ¸ ì´ˆê¸°í™”"""
        await super().initialize()
        await self.streams_client.initialize()
    
    async def cleanup(self):
        """ì—ì´ì „íŠ¸ ì •ë¦¬"""
        await self.streams_client.close()
        await super().cleanup()
    
    async def run_subscriber(self):
        """Streamsì™€ pub/sub ê¸°ë°˜ ë©”ì‹œì§€ ìˆ˜ì‹ """
        self.logger.info("ğŸš€ AnswerGeneratorAgent Streams + pub/sub êµ¬ë… ì‹œì‘")
        
        # pub/sub êµ¬ë… ì‹œì‘ (ë³„ë„ íƒœìŠ¤í¬ë¡œ ì‹¤í–‰)
        pubsub_task = asyncio.create_task(self.run_pubsub_subscriber())
        
        try:
            while True:
                try:
                    # Streamsì—ì„œ ë©”ì‹œì§€ ìˆ˜ì‹  - ëŒ€ìš©ëŸ‰ ë™ì‹œ ì²˜ë¦¬ (ìµœëŒ€ 50ê°œ)
                    messages = await self.streams_client.read_from_backend_stream(count=50, block=1000)
                    
                    if messages:
                        # ë™ì‹œ ì²˜ë¦¬í•  ë©”ì‹œì§€ë“¤ ë¶„ë¥˜
                        tasks = []
                        for msg_id, fields in messages:
                            self.logger.info(f"ğŸ“¥ Streamsì—ì„œ ë©”ì‹œì§€ ìˆ˜ì‹ : {msg_id}")
                            
                            # ë©”ì‹œì§€ íŒŒì‹± (ì´ë¯¸ decodeëœ ë¬¸ìì—´)
                            message_type = fields.get('type', '')
                            target_agent = fields.get('target_agent', '')
                            
                            self.logger.info(f"ğŸ” ë©”ì‹œì§€ ë¶„ì„: type={message_type}, target_agent={target_agent}")
                            
                            # msg_idê°€ bytesì¸ ê²½ìš°ì—ë§Œ decode, ì´ë¯¸ ë¬¸ìì—´ì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                            msg_id_str = msg_id.decode() if isinstance(msg_id, bytes) else str(msg_id)
                            
                            # ìê¸° ì—ì´ì „íŠ¸ë¡œ ì˜¨ ë©”ì‹œì§€ê°€ ì•„ë‹ˆë©´ ACKí•˜ê³  ê±´ë„ˆë›°ê¸°
                            if target_agent not in ["AnswerGeneratorAgent", "AnswerGenerator"]:
                                tasks.append(self.streams_client.ack_stream_message(msg_id_str))
                                continue
                            
                            # ë©”ì‹œì§€ ì²˜ë¦¬ íƒœìŠ¤í¬ ìƒì„±
                            if message_type == "generate_answer":
                                tasks.append(self._handle_answer_generation_stream(fields, msg_id_str))
                            else:
                                self.logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì‹œì§€ íƒ€ì…: {message_type}")
                                tasks.append(self.streams_client.ack_stream_message(msg_id_str))
                        
                        # ëª¨ë“  ë©”ì‹œì§€ ë™ì‹œ ì²˜ë¦¬
                        if tasks:
                            await asyncio.gather(*tasks, return_exceptions=True)
                    
                    await asyncio.sleep(0.1)
                    
                except Exception as e:
                    self.logger.error(f"Streams ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                    await asyncio.sleep(0.1)
        
        finally:
            # pub/sub íƒœìŠ¤í¬ ì •ë¦¬
            pubsub_task.cancel()
            try:
                await pubsub_task
            except asyncio.CancelledError:
                pass
    
    async def run_pubsub_subscriber(self):
        """pub/sub ê¸°ë°˜ ë©”ì‹œì§€ ìˆ˜ì‹  (AnswerGeneratorAgent ì „ìš©)"""
        self.logger.info("ğŸš€ AnswerGeneratorAgent pub/sub êµ¬ë… ì‹œì‘")
        
        async def message_handler(channel: str, payload: Dict[str, Any]):
            try:
                target_agent = payload.get("target_agent")
                message_type = payload.get("type")
                
                # ìê¸° ì—ì´ì „íŠ¸ë¡œ ì˜¨ ë©”ì‹œì§€ê°€ ì•„ë‹ˆë©´ ì¦‰ì‹œ ë¦¬í„´
                if target_agent not in ["AnswerGeneratorAgent", "AnswerGenerator"]:
                    return
                
                self.logger.info(f"ğŸ“¥ pub/sub ë©”ì‹œì§€ ìˆ˜ì‹ : channel={channel}, target_agent={target_agent}, type={message_type}")
                self.logger.info(f"ğŸ” payload ë‚´ìš©: {payload}")
                
                if message_type in ["READY_FOR_ANSWER", "ready_for_answer"]:
                    self.logger.info(f"ğŸ”„ READY_FOR_ANSWER ì²˜ë¦¬ ì‹œì‘ (ë³‘ë ¬)")
                    # BaseAgentì˜ ë³‘ë ¬ ì²˜ë¦¬ ë©”ì„œë“œ ì‚¬ìš© (await ì—†ì´)
                    asyncio.create_task(self.process_message_parallel(message_type, payload))
                elif message_type in ["GENERATE_ANSWER", "generate_answer"]:
                    self.logger.info(f"ğŸ”„ GENERATE_ANSWER ì²˜ë¦¬ ì‹œì‘ (ë³‘ë ¬)")
                    # BaseAgentì˜ ë³‘ë ¬ ì²˜ë¦¬ ë©”ì„œë“œ ì‚¬ìš© (await ì—†ì´)
                    asyncio.create_task(self.process_message_parallel(message_type, payload))
                else:
                    self.logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” pub/sub ë©”ì‹œì§€ íƒ€ì…: {message_type}")
                    
            except Exception as e:
                self.logger.error(f"pub/sub ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        
        # AGENT_TO_AGENT ì±„ë„ êµ¬ë…
        from agents.common.event_bus import subscribe_and_listen, AGENT_TO_AGENT
        await subscribe_and_listen([AGENT_TO_AGENT], message_handler, self)
        self.logger.info("âœ… AnswerGeneratorAgent pub/sub ë©”ì‹œì§€ êµ¬ë… ì‹œì‘")
    
    async def process_answer_generation_request(self, payload: Dict[str, Any]):
        """pub/subìœ¼ë¡œ ë°›ì€ ë‹µë³€ ìƒì„± ìš”ì²­ ì²˜ë¦¬"""
        import time
        start_time = time.time()
        
        try:
            # ë©”íŠ¸ë¦­: ìš”ì²­ ì‹œì‘
            if self.metrics:
                self.metrics.increment_counter("answer_requests_total")
                self.metrics.set_gauge("active_sessions", len(self.processed_sessions) + 1)
            
            self.logger.info(f"ğŸ” process_answer_generation_request ì‹œì‘")
            self.logger.info(f"ğŸ” payload íƒ€ì…: {type(payload)}")
            self.logger.info(f"ğŸ” payload í‚¤ë“¤: {list(payload.keys()) if isinstance(payload, dict) else 'NOT_DICT'}")
            
            session_id = payload.get("session_id")
            question = payload.get("question", "")
            context = payload.get("context", "")
            
            self.logger.info(f"ğŸ” session_id: {session_id}")
            self.logger.info(f"ğŸ” question ê¸¸ì´: {len(question)}")
            self.logger.info(f"ğŸ” context íƒ€ì…: {type(context)}")
            
            # QuestionImprovementì—ì„œ ì§ì ‘ ë³´ë‚¸ ë©”ì‹œì§€ì¸ì§€ í™•ì¸
            from_agent = payload.get("from_agent")
            self.logger.info(f"ğŸ” from_agent ê°’: '{from_agent}'")
            self.logger.info(f"ğŸ” from_agent íƒ€ì…: {type(from_agent)}")
            self.logger.info(f"ğŸ” payload ì „ì²´: {payload}")
            
            # evaluation_data ì´ˆê¸°í™”
            evaluation_data = {}
            
            if from_agent == "QuestionImprovement":
                # QuestionImprovementì—ì„œ ë³´ë‚¸ ê°„ì†Œí™”ëœ ë©”ì‹œì§€ êµ¬ì¡° ì²˜ë¦¬
                evaluation_data = {
                    "knowledge_code": payload.get("knowledge_code", "K1"),
                    "quality": payload.get("quality", "answerable"),
                    "unanswerable_reason": payload.get("unanswerable_reason", ""),
                    "clarification_attempts": payload.get("clarification_attempts", 0),
                    "original_question": payload.get("original_question", payload.get("question", ""))
                }
                self.logger.info(f"ğŸ”„ QuestionImprovementì—ì„œ ì˜¨ ë‹µë³€ ìš”ì²­: ì„¸ì…˜ {session_id}")
                self.logger.info(f"ğŸ“ ì§ˆë¬¸: {question}")
                self.logger.info(f"ğŸ” knowledge_code: {evaluation_data['knowledge_code']}")
                self.logger.info(f"ğŸ” quality: {evaluation_data['quality']}")
            else:
                # ê¸°ì¡´ ë°±ì—”ë“œì—ì„œ ì˜¨ ë©”ì‹œì§€ êµ¬ì¡° ì²˜ë¦¬
                classification_result = payload.get("classification_result", {})
                evaluation_data = classification_result if classification_result else payload.get("evaluation", {})
                
                self.logger.info(f"ğŸ”„ ë°±ì—”ë“œì—ì„œ ì˜¨ ë‹µë³€ ìš”ì²­: ì„¸ì…˜ {session_id}")
                self.logger.info(f"ğŸ“ ì§ˆë¬¸: {question}")
                self.logger.info(f"ğŸ” classification_result: {classification_result}")
                self.logger.info(f"ğŸ” evaluation_data: {evaluation_data}")
                self.logger.info(f"ğŸ” evaluation_data['quality']: {evaluation_data.get('quality', 'NOT_FOUND')}")
            
            # ì²˜ë¦¬ ë¡œê·¸ ë°œí–‰
            await self._publish_processing_log(session_id, "answer_start", "ë‹µë³€ ìƒì„± ì‹œì‘")
            
            # ë‹µë³€ ìƒì„±
            self.logger.info(f"ğŸ” _generate_answer í˜¸ì¶œ ì „ evaluation_data: {evaluation_data}")
            result = await self._generate_answer(
                question=question,
                context=context,
                evaluation=evaluation_data,
                session_id=session_id
            )
            
            # ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
            duration = time.time() - start_time
            
            if result:
                # ë©”íŠ¸ë¦­: ì„±ê³µ
                if self.metrics:
                    self.metrics.record_request("answer_generation", success=True, duration=duration)
                    self.metrics.increment_counter("answer_success_total")
                
                # resultê°€ ë¬¸ìì—´ì¸ ê²½ìš° ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                if isinstance(result, str):
                    result = {
                        "educational_answer": result,
                        "knowledge_code": evaluation_data.get("knowledge_code", "K1"),
                        "answerability": evaluation_data.get("quality", "answerable"),
                        "clarification_used": False,
                        "context_used": len(context) if context else 0
                    }
                
                # ë‹µë³€ ê²°ê³¼ë¥¼ Streamsë¡œ ë°±ì—”ë“œì— ì „ì†¡
                await self._send_answer_to_backend(session_id, result)
                
                # ObserverAgentì—ê²Œ ìš”ì•½ ìš”ì²­ ì „ì†¡
                await self._trigger_observer_summary(session_id, question, result["educational_answer"], result)
                
                # ì²˜ë¦¬ ë¡œê·¸ ë°œí–‰
                await self._publish_processing_log(session_id, "answer_complete", "ë‹µë³€ ìƒì„± ì™„ë£Œ")
                
                self.logger.info(f"âœ… ë‹µë³€ ìƒì„± ë° ì „ì†¡ ì™„ë£Œ: ì„¸ì…˜ {session_id}")
            else:
                # ë©”íŠ¸ë¦­: ì‹¤íŒ¨
                if self.metrics:
                    self.metrics.record_request("answer_generation", success=False, duration=duration)
                    self.metrics.increment_counter("answer_failed_total")
                    self.metrics.record_error("generation_failed", "answer_generation")
                
                # ì²˜ë¦¬ ë¡œê·¸ ë°œí–‰
                await self._publish_processing_log(session_id, "answer_failed", "ë‹µë³€ ìƒì„± ì‹¤íŒ¨")
                
                self.logger.error(f"âŒ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: ì„¸ì…˜ {session_id}")
                
        except Exception as e:
            # ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
            duration = time.time() - start_time
            
            # ë©”íŠ¸ë¦­: ì—ëŸ¬
            if self.metrics:
                self.metrics.record_request("answer_generation", success=False, duration=duration)
                self.metrics.record_error("exception", "answer_generation")
            
            # ì²˜ë¦¬ ë¡œê·¸ ë°œí–‰
            try:
                await self._publish_processing_log(session_id, "answer_error", f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            except:
                pass
            
            self.logger.error(f"âŒ ë‹µë³€ ìƒì„± ìš”ì²­ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        finally:
            # ë©”íŠ¸ë¦­: í™œì„± ì„¸ì…˜ ê°ì†Œ
            if self.metrics:
                self.metrics.set_gauge("active_sessions", len(self.processed_sessions))
    
    async def _send_answer_to_backend(self, session_id: int, result: Dict[str, Any]):
        """Streamsë¡œ ë°±ì—”ë“œì— ë‹µë³€ ê²°ê³¼ ì „ì†¡"""
        try:
            answer = result.get("educational_answer", "")
            knowledge_code = result.get("knowledge_code", "K1")
            answerability = result.get("answerability", "answerable")
            clarification_used = result.get("clarification_used", False)
            context_used = result.get("context_used", 0)
            
            # ë””ë²„ê¹…: ì‹¤ì œ answer ê¸¸ì´ í™•ì¸
            self.logger.info(f"ğŸ” ì „ì†¡í•  answer ê¸¸ì´: {len(answer)}ì")
            self.logger.info(f"ğŸ” answer ëë¶€ë¶„(ë§ˆì§€ë§‰ 100ì): ...{answer[-100:] if len(answer) > 100 else answer}")
            
            # Streamsë¡œ ë‹µë³€ ê²°ê³¼ ì „ì†¡
            await self.streams_client.send_to_backend_stream({
                "type": MessageType.ANSWER_RESULT,
                "session_id": session_id,
                "answer": answer,
                "knowledge_code": knowledge_code,
                "answerability": answerability,
                "clarification_used": clarification_used,
                "context_used": context_used,
                "timestamp": datetime.now().isoformat()
            })
            
            self.logger.info(f"ğŸ“¤ ë°±ì—”ë“œì— ë‹µë³€ ê²°ê³¼ ì „ì†¡: ì„¸ì…˜ {session_id}, ë‹µë³€ ê¸¸ì´ {len(answer)}ì")
            
        except Exception as e:
            self.logger.error(f"âŒ ë°±ì—”ë“œ ë‹µë³€ ì „ì†¡ ì˜¤ë¥˜: {e}")
            raise
    
    async def _trigger_observer_summary(self, session_id: int, question: str, answer: str, result: Dict[str, Any]):
        """ObserverAgentì—ê²Œ ìš”ì•½ ìš”ì²­ ì „ì†¡ (pub/sub)"""
        try:
            conversation_text = f"""í•™ìƒ ì§ˆë¬¸: {question}

ì—ì´ì „íŠ¸ ë‹µë³€: {answer}

ì¶”ê°€ ì •ë³´:
- ì§€ì‹ ìœ í˜•: {result.get('knowledge_code', 'K1')}
- ë‹µë³€ ê°€ëŠ¥ì„±: {result.get('answerability', 'answerable')}
- ëª…ë£Œí™” ì‚¬ìš©: {result.get('clarification_used', False)}
- ë§¥ë½ ì‚¬ìš©: {result.get('context_used', 0)}ì"""
            
            from agents.common.event_bus import publish_event, AGENT_TO_AGENT
            
            # request_id ìƒì„± (UUID ì‚¬ìš©)
            import uuid
            request_id = str(uuid.uuid4())
            
            await publish_event(
                AGENT_TO_AGENT,
                {
                    "type": "generate_summary",
                    "target_agent": "ObserverAgent",
                    "session_id": session_id,
                    "request_id": request_id,
                    "conversation_text": conversation_text,
                    "question": question,
                    "answer": answer,
                    "context": {
                        "knowledge_code": result.get('knowledge_code', 'K1'),
                        "answerability": result.get('answerability', 'answerable'),
                        "clarification_used": result.get('clarification_used', False),
                        "context_used": result.get('context_used', 0)
                    },
                    "timestamp": datetime.now().isoformat()
                }
            )
            
            self.logger.info(f"ğŸ“¤ ObserverAgentì—ê²Œ ìš”ì•½ ìš”ì²­ ì „ì†¡: ì„¸ì…˜ {session_id}")
            
        except Exception as e:
            self.logger.error(f"âŒ ObserverAgent ìš”ì•½ ìš”ì²­ ì „ì†¡ ì˜¤ë¥˜: {e}")
    
    
    
    
    
    async def _generate_answer(self, question: str, context: str, evaluation: dict, session_id: int = None) -> Dict[str, Any]:
        """ë‹µë³€ ìƒì„± - ê¸°ì¡´ PromptGeneratorTool ë¡œì§ì„ í•¨ìˆ˜ë¡œ ë³€í™˜"""
        try:
            self.logger.info(f"ë‹µë³€ ìƒì„± ì‹œì‘: {question[:50]}...")
            
            # ì§ˆë¬¸ ìœ í˜•ê³¼ ë‹µë³€ ê°€ëŠ¥ ì—¬ë¶€ ì¶”ì¶œ
            knowledge_code = evaluation.get("knowledge_code", "K1")
            quality = evaluation.get("quality", "")
            
            # ë””ë²„ê¹…: evaluation ë°ì´í„° ë¡œê·¸ ì¶œë ¥
            self.logger.info(f"ğŸ” evaluation ì „ì²´ ë°ì´í„°: {evaluation}")
            self.logger.info(f"ğŸ” ë¶„ë¥˜ ê²°ê³¼ - knowledge_code: {knowledge_code}, quality: '{quality}'")
            
            # quality ê°’ì— ë”°ë¥¸ ì²˜ë¦¬ (AnswerGeneratorëŠ” answerable ì§ˆë¬¸ë§Œ ì²˜ë¦¬)
            if quality == "" or quality == AnswerabilityType.UNANSWERABLE:
                answerability = AnswerabilityType.UNANSWERABLE
                self.logger.info(f"ğŸš« unanswerableë¡œ íŒì •: quality='{quality}'")
            elif quality == AnswerabilityType.NEEDS_CLARIFY:
                # AnswerGeneratorëŠ” needs_clarifyë¥¼ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ - ì´ëŠ” QuestionClassifierì—ì„œ ì²˜ë¦¬ë˜ì–´ì•¼ í•¨
                self.logger.error(f"âŒ AnswerGeneratorê°€ needs_clarify ì§ˆë¬¸ì„ ë°›ì•˜ìŠµë‹ˆë‹¤: quality='{quality}' - ì´ëŠ” QuestionClassifierì—ì„œ ì²˜ë¦¬ë˜ì–´ì•¼ í•©ë‹ˆë‹¤")
                return {"error": "needs_clarify ì§ˆë¬¸ì€ AnswerGeneratorê°€ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "success": False}
            else:
                answerability = quality
                self.logger.info(f"âœ… answerableë¡œ íŒì •: quality='{quality}'")
            
            # unanswerable ì§ˆë¬¸ì— ëŒ€í•œ ê³ ì •ëœ ì‘ë‹µ (LLM í˜¸ì¶œ ì—†ìŒ)
            if answerability == AnswerabilityType.UNANSWERABLE or quality == "unanswerable":
                self.logger.info("ğŸš« unanswerable ì§ˆë¬¸ - ê³ ì •ëœ ê±°ì ˆ ì‘ë‹µ ë°˜í™˜")
                
                # ê±°ì ˆ ì´ìœ ì— ë”°ë¼ ë‹¤ë¥¸ ë©”ì‹œì§€ ë°˜í™˜
                unanswerable_reason = evaluation.get("unanswerable_reason", "")
                if unanswerable_reason == "clarification_failed":
                    actual_answer = self._get_clarification_failed_response(evaluation)
                else:
                    actual_answer = self._get_fixed_unanswerable_response()
                
                result = {
                    "educational_answer": actual_answer,
                    "prompt_used": "ê³ ì •ëœ ê±°ì ˆ ì‘ë‹µ",
                    "success": True,
                    "question": question,
                    "knowledge_code": knowledge_code,
                    "answerability": answerability,
                    "unanswerable": True
                }
                return result
            
            # ìƒí™©ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._select_prompt_by_type(knowledge_code, answerability, question, context, evaluation)
            
            # ë§¥ë½ ì •ë³´ ì¶”ê°€
            enhanced_prompt = self._enhance_prompt_with_context(prompt, context, evaluation)
            
            # LLMì„ í†µí•´ ì‹¤ì œ êµìœ¡ì  ë‹µë³€ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)
            self.logger.info("LLMì„ í†µí•´ ì‹¤ì œ ë‹µë³€ ìƒì„± ì‹œì‘...")
            actual_answer = await self._generate_answer_with_llm(question, enhanced_prompt, context, session_id, knowledge_code, answerability)
            
            result = {
                "educational_answer": actual_answer,
                "prompt_used": enhanced_prompt,
                "success": True,
                "question": question,
                "context_used": len(context),
                "evaluation_used": evaluation is not None,
                "clarification_used": False,
                "knowledge_code": knowledge_code,
                "answerability": answerability
            }

            self.logger.info(f"ë‹µë³€ ìƒì„± ì™„ë£Œ: {len(actual_answer)}ì")
            self.logger.info(f"ğŸ” actual_answer ëë¶€ë¶„(ë§ˆì§€ë§‰ 100ì): ...{actual_answer[-100:] if len(actual_answer) > 100 else actual_answer}")
            return result

        except Exception as e:
            self.logger.error(f"ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
            return {"error": str(e), "success": False}
    
    
    def _select_prompt_by_type(self, knowledge_code: str, answerability: str, question: str = "", context: str = "", evaluation: dict = None) -> str:
        """ì§ˆë¬¸ ìœ í˜•ë³„ í”„ë¡¬í”„íŠ¸ ì„ íƒ - YAML ê¸°ë°˜"""
        self.logger.info(f"ğŸ” í”„ë¡¬í”„íŠ¸ ì„ íƒ: knowledge_code={knowledge_code}, answerability={answerability}")
        
        # ë‹µë³€ ë¶ˆê°€ëŠ¥í•œ ì§ˆë¬¸ì— ëŒ€í•œ íŠ¹ë³„ ì²˜ë¦¬
        if answerability == AnswerabilityType.UNANSWERABLE:
            self.logger.info(f"ğŸš« ë‹µë³€ ë¶ˆê°€ëŠ¥í•œ ì§ˆë¬¸ìœ¼ë¡œ ë¶„ë¥˜ë¨ - ìˆ˜í•™ ì™¸ ì˜ì—­ ì•ˆë‚´ ë©”ì‹œì§€ ìƒì„±")
            return self._get_unanswerable_prompt()
        
        # prompt_config êµ¬ì¡°ì— ë”°ë¼ ì ‘ê·¼ ë°©ì‹ ê²°ì •
        if "templates" in self.prompt_config:
            # prompt_configê°€ ì§ì ‘ answer_generator ì„¤ì •ì¸ ê²½ìš°
            templates = self.prompt_config.get("templates", {})
        elif "answer_generator" in self.prompt_config:
            # prompt_configê°€ ì „ì²´ ì„¤ì •ì´ê³  answer_generator í‚¤ê°€ ìˆëŠ” ê²½ìš°
            answer_generator_config = self.prompt_config.get("answer_generator", {})
            templates = answer_generator_config.get("templates", {})
        else:
            self.logger.error(f"âŒ templatesë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            templates = {}
        
        # PromptBuilderë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ìƒì„±
        try:
            # ë³€ìˆ˜ ì¤€ë¹„
            variables = {
                "knowledge_type": knowledge_code,
                "original_question": question,
                "clarification_summary": evaluation.get("clarification_summary", "ì—†ìŒ"),
                "answer_structure": self._get_answer_structure(knowledge_code),
                "tone_guide": self.prompt_builder.get_setting("answer_generator", "common.tone") or "ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ êµì‚¬ í†¤",
                "language_guide": self.prompt_builder.get_setting("answer_generator", "common.language") or "í•œêµ­ì–´, ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì— ë§ëŠ” í‘œí˜„",
                "structure_guide": self.prompt_builder.get_setting("answer_generator", "common.structure") or "ì²´ê³„ì ì´ê³  ë…¼ë¦¬ì ì¸ êµ¬ì„±",
                "examples_guide": self.prompt_builder.get_setting("answer_generator", "common.examples") or "êµ¬ì²´ì ì´ê³  ì‹¤ì œì ì¸ ì˜ˆì‹œ í¬í•¨",
                "clarification_when_used": self.prompt_builder.get_setting("answer_generator", "clarification_integration.when_used") or "ëª…ë£Œí™” ê³¼ì •ì„ ê±°ì¹œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€",
                "clarification_approach": self.prompt_builder.get_setting("answer_generator", "clarification_integration.approach") or "ëª…ë£Œí™” ì‘ë‹µì„ ë°”íƒ•ìœ¼ë¡œ ë” ì •í™•í•˜ê³  ë§ì¶¤í˜• ë‹µë³€ ìƒì„±",
                "clarification_structure": self.prompt_builder.get_setting("answer_generator", "clarification_integration.structure") or "ëª…ë£Œí™” ê³¼ì • ìš”ì•½, ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ë‹µë³€, ì¶”ê°€ ì„¤ëª… ë° ì˜ˆì‹œ",
                "formatting_rules": self.prompt_builder.get_setting("answer_generator", "formatting_rules") or "ëª¨ë“  ìˆ˜í•™ ìˆ˜ì‹ì€ LaTeX í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”"
            }
            
            # PromptBuilderë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self.prompt_builder.build_prompt(
                template_name="answer_generation", 
                agent_name="answer_generator",
                variables=variables
            )
            template = prompt.get("system", "")
            
            self.logger.info(f"ğŸ” PromptBuilderë¡œ ìƒì„±ëœ í…œí”Œë¦¿ ê¸¸ì´: {len(template)}")
            
            if not template:
                raise ValueError(f"PromptBuilderì—ì„œ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨")
                
            return template
            
        except Exception as e:
            self.logger.error(f"âŒ PromptBuilder ì‚¬ìš© ì¤‘ ì˜¤ë¥˜: {e}")
            # í´ë°±: ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©
            answer_generation_template = templates.get("answer_generation", {})
            template = answer_generation_template.get("system", "")
            return template
    
    def _get_answer_structure(self, knowledge_code: str) -> str:
        """ë‹µë³€ ìœ í˜•ë³„ êµ¬ì¡° ê°€ì ¸ì˜¤ê¸°"""
        settings = self.prompt_config.get("settings", {})
        answer_types = settings.get("answer_types", {})
        answer_type_config = answer_types.get(knowledge_code.lower(), {})
        
        structure_list = answer_type_config.get("structure", [])
        if structure_list:
            return "\n".join([f"- {item}" for item in structure_list])
        else:
            return "ê¸°ë³¸ ë‹µë³€ êµ¬ì¡°"
    
    def _get_fixed_unanswerable_response(self) -> str:
        """unanswerable ì§ˆë¬¸ì— ëŒ€í•œ ê³ ì •ëœ ê±°ì ˆ ì‘ë‹µ"""
        return "ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š MAICEëŠ” ìˆ˜í•™ í•™ìŠµì„ ë„ì™€ì£¼ëŠ” AI íŠœí„°ì…ë‹ˆë‹¤. í˜„ì¬ëŠ” ìˆ˜í•™ êµê³¼ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ë§Œ ë‹µë³€í•´ë“œë¦´ ìˆ˜ ìˆì–´ìš”. ìˆ˜í•™ ë¬¸ì œë‚˜ ê°œë…ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ì§ˆë¬¸í•´ì£¼ì„¸ìš”! ğŸ“šâœ¨"
    
    def _get_clarification_failed_response(self, evaluation: dict) -> str:
        """ëª…ë£Œí™” ì‹¤íŒ¨ë¡œ ì¸í•œ ê±°ì ˆ ì‘ë‹µ (ì •í•´ì§„ ë©”ì‹œì§€)"""
        original_question = evaluation.get("original_question", "ì§ˆë¬¸")
        clarification_attempts = evaluation.get("clarification_attempts", 3)
        
        return f"""ì£„ì†¡í•©ë‹ˆë‹¤! ğŸ˜…

**'{original_question}'** ì§ˆë¬¸ì— ëŒ€í•´ {clarification_attempts}ë²ˆì˜ ëª…ë£Œí™”ë¥¼ ì‹œë„í–ˆì§€ë§Œ, ëª…í™•í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ì–´ë ¤ìš´ ìƒí™©ì…ë‹ˆë‹¤.

## ğŸ”„ **ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”**
ë” êµ¬ì²´ì ì´ê³  ëª…í™•í•œ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ë¬¼ì–´ë³´ì‹œë©´ ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ’¡ **ì¢‹ì€ ì§ˆë¬¸ ì˜ˆì‹œ**:
- **"ì§€ìˆ˜í•¨ìˆ˜ì˜ ì •ì˜ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”"**
- **"ë¡œê·¸ì˜ ì„±ì§ˆì„ ì„¤ëª…í•´ì£¼ì„¸ìš”"**  
- **"ì‚¼ê°í•¨ìˆ˜ sin, cos, tanì˜ ê´€ê³„ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”"**
- **"ë“±ì°¨ìˆ˜ì—´ì˜ ì¼ë°˜í•­ êµ¬í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”"**
- **"ìˆ˜í•™ì  ê·€ë‚©ë²•ìœ¼ë¡œ ì¦ëª…í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”"**

## ğŸ¯ **ì§ˆë¬¸ íŒ**
- êµ¬ì²´ì ì¸ ìˆ˜í•™ ê°œë…ì´ë‚˜ ë¬¸ì œë¥¼ ëª…ì‹œí•´ì£¼ì„¸ìš”
- "ì–´ë–¤ ë¶€ë¶„"ì´ ê¶ê¸ˆí•œì§€ êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ì£¼ì„¸ìš”
- ì˜ˆì‹œë‚˜ êµ¬ì²´ì ì¸ ë¬¸ì œê°€ ìˆìœ¼ë©´ í•¨ê»˜ ì•Œë ¤ì£¼ì„¸ìš”

ìƒˆë¡œìš´ ì§ˆë¬¸ì„ ê¸°ë‹¤ë¦¬ê³  ìˆê² ìŠµë‹ˆë‹¤! ğŸ˜Š í•¨ê»˜ ìˆ˜í•™ì„ ê³µë¶€í•´ë´ìš”! ğŸ’ª"""
    
    # def _get_unanswerable_prompt(self) -> str:
    #     """ë‹µë³€ ë¶ˆê°€ëŠ¥í•œ ì§ˆë¬¸ì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸ ìƒì„± - DEPRECATED: ì‚¬ìš©í•˜ì§€ ì•ŠìŒ"""
    #     return """ë‹¹ì‹ ì€ ìˆ˜í•™ êµìœ¡ ì „ë¬¸ AI MAICEì…ë‹ˆë‹¤. 
    # 
    # í•™ìƒì´ ìˆ˜í•™ ì™¸ì˜ ì˜ì—­ì— ëŒ€í•œ ì§ˆë¬¸ì„ í–ˆìŠµë‹ˆë‹¤. ì´ ê²½ìš° ë‹¤ìŒê³¼ ê°™ì´ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤:
    # 
    # **ì‘ë‹µ ì›ì¹™:**
    # - ìˆ˜í•™ êµê³¼ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ë§Œ ë‹µë³€ ê°€ëŠ¥í•˜ë‹¤ëŠ” ì ì„ ì¹œê·¼í•˜ê²Œ ì•ˆë‚´
    # - ìˆ˜í•™ ê´€ë ¨ ì§ˆë¬¸ì„ ìš”ì²­í•˜ëŠ” ë©”ì‹œì§€ ì œê³µ
    # - ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ í†¤ìœ¼ë¡œ ì‘ë‹µ
    # 
    # **ì‘ë‹µ í˜•ì‹:**
    # ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š MAICEëŠ” ìˆ˜í•™ í•™ìŠµì„ ë„ì™€ì£¼ëŠ” AI íŠœí„°ì…ë‹ˆë‹¤. 
    # í˜„ì¬ëŠ” ìˆ˜í•™ êµê³¼ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ë§Œ ë‹µë³€í•´ë“œë¦´ ìˆ˜ ìˆì–´ìš”. 
    # ìˆ˜í•™ ë¬¸ì œë‚˜ ê°œë…ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ì§ˆë¬¸í•´ì£¼ì„¸ìš”! ğŸ“šâœ¨
    # 
    # **ì‘ë‹µ ì‹œ ì£¼ì˜ì‚¬í•­:**
    # - ìˆ˜í•™ ì™¸ ì˜ì—­ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‹µë³€ì€ ì œê³µí•˜ì§€ ì•ŠìŒ
    # - ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ í†¤ ìœ ì§€
    # - ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ì¹œê·¼ê° í‘œí˜„
    # - ìˆ˜í•™ ê´€ë ¨ ì§ˆë¬¸ì„ ìœ ë„í•˜ëŠ” ë©”ì‹œì§€ë¡œ ë§ˆë¬´ë¦¬
    # - ì§ˆë¬¸ê³¼ ì—°ê´€ëœ ìˆ˜í•™ ê°œë…ë“¤ì„ ì°½ì˜ì ìœ¼ë¡œ ì—°ê²°
    # - êµ¬ì²´ì ì´ê³  ì‹¤ìƒí™œê³¼ ì—°ê´€ëœ ì˜ˆì‹œ ì œì‹œ
    # - ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤ ìœ ì§€
    # - ì´ëª¨ì§€ ì ì ˆíˆ ì‚¬ìš©"""
    
    def _enhance_prompt_with_context(self, prompt: str, context: str, evaluation: dict) -> str:
        """í”„ë¡¬í”„íŠ¸ì— ë§¥ë½ ì •ë³´ ì¶”ê°€"""
        try:
            # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ì— ë§¥ë½ ì •ë³´ ì¶”ê°€
            if context:
                context_section = f"\n\n## ë§¥ë½ ì •ë³´:\n{context}\n"
                prompt = prompt + context_section
            
            # í‰ê°€ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if evaluation:
                knowledge_code = evaluation.get("knowledge_code", "K1")
                quality = evaluation.get("quality", "answerable")
                
                evaluation_section = f"\n\n## ì§ˆë¬¸ ë¶„ì„ ì •ë³´:\n- ì§ˆë¬¸ ìœ í˜•: {knowledge_code}\n- ë‹µë³€ ê°€ëŠ¥ì„±: {quality}\n"
                prompt = prompt + evaluation_section
            
            return prompt
            
        except Exception as e:
            self.logger.error(f"í”„ë¡¬í”„íŠ¸ ë§¥ë½ ì¶”ê°€ ì˜¤ë¥˜: {e}")
            return prompt  # ì˜¤ë¥˜ ì‹œ ì›ë³¸ í”„ë¡¬í”„íŠ¸ ë°˜í™˜
    
    
    async def _generate_answer_with_llm(self, question: str, prompt: str, context: str = "", session_id: int = None, knowledge_code: str = "", answerability: str = "") -> str:
        """LLMì„ í†µí•´ ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€ ìƒì„± ë° ì‹¤ì‹œê°„ ë°±ì—”ë“œ ì „ì†¡ - LLM íˆ´ ì‚¬ìš©"""
        try:
            # í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ ì¤€ë¹„
            variables = {
                "question": question,
                "knowledge_type": knowledge_code if knowledge_code else "ë¯¸ë¶„ë¥˜",
                "original_question": question,
                "clarification_summary": "ëª…ë£Œí™” ê³¼ì •ì„ ê±°ì³ êµ¬ì²´í™”ëœ ì§ˆë¬¸",
                "answerability": answerability if answerability else "ë¯¸ë¶„ë¥˜",
                "context": context if context else "ì—†ìŒ"
            }
            
            # ì´ë¯¸ _select_prompt_by_typeì—ì„œ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            # promptëŠ” ì´ë¯¸ ë³€ìˆ˜ ì¹˜í™˜ì´ ì™„ë£Œëœ ìƒíƒœ
            
            # PromptBuilderì—ì„œ ìƒì„±ëœ ì „ì²´ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© (system + user í…œí”Œë¦¿ ëª¨ë‘ í¬í•¨)
            full_prompt = self.prompt_builder.build_prompt(
                template_name="answer_generation", 
                agent_name="answer_generator",
                variables=variables
            )
            
            # LLM íˆ´ë¡œ ë‹µë³€ ìƒì„± - create_answer_generator_tool()ì˜ ê¸°ë³¸ ì„¤ì • ì‚¬ìš© (max_tokens=4000, stream=True, timeout=60)
            result = await self.llm_tool.execute(
                prompt=full_prompt,
                variables=variables,
                session_id=session_id,
                streams_client=self.streams_client
            )
            
            if not result["success"]:
                return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {result['error']}"
            
            # LLM toolsì—ì„œ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì–´ content ë°˜í™˜
            full_answer = result["content"] if isinstance(result, dict) else str(result)
            
            # ë””ë²„ê¹…: LLMì—ì„œ ë°›ì€ ë‹µë³€ ê¸¸ì´ í™•ì¸
            self.logger.info(f"ğŸ” LLMì—ì„œ ë°›ì€ full_answer ê¸¸ì´: {len(full_answer)}ì")
            self.logger.info(f"ğŸ” full_answer ëë¶€ë¶„(ë§ˆì§€ë§‰ 100ì): ...{full_answer[-100:] if len(full_answer) > 100 else full_answer}")
            
            # ì‹¤ì‹œê°„ ì²­í¬ ì „ì†¡ì€ LLM toolsì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨
            # ì¶”ê°€ì ì¸ ì²­í¬ ì „ì†¡ì€ ë¶ˆí•„ìš”
            
            return full_answer
            
        except Exception as e:
            self.logger.error(f"LLM ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
            return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    async def _send_answer_to_backend_realtime(self, session_id: int, full_answer: str):
        """ì‹¤ì‹œê°„ ë‹µë³€ ì „ì†¡ (ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• )"""
        try:
            # ë‹µë³€ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í•  (15ìì”©)
            chunk_size = 15
            chunks = [full_answer[i:i+chunk_size] for i in range(0, len(full_answer), chunk_size)]
            
            self.logger.info(f"ğŸ“¤ ì‹¤ì‹œê°„ ë‹µë³€ ì „ì†¡ ì‹œì‘: {len(chunks)}ê°œ ì²­í¬")
            
            # ê° ì²­í¬ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì „ì†¡
            for i, chunk in enumerate(chunks, 1):
                await self._send_answer_chunk_to_backend(session_id, chunk, i)
                # ì‹¤ì‹œê°„ ëŠë‚Œì„ ìœ„í•´ ì•½ê°„ì˜ ì§€ì—°
                await asyncio.sleep(0.05)
            
            # ìµœì¢… ì²­í¬ ì „ì†¡
            await self._send_final_chunk(session_id, len(chunks))
            
            self.logger.info(f"âœ… ì‹¤ì‹œê°„ ë‹µë³€ ì „ì†¡ ì™„ë£Œ: ì„¸ì…˜ {session_id}")
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹¤ì‹œê°„ ë‹µë³€ ì „ì†¡ ì˜¤ë¥˜: {e}")
    
    
    async def _send_answer_chunk_to_backend(self, session_id: int, chunk: str, chunk_index: int):
        """ë‹µë³€ ì²­í¬ë¥¼ ë°±ì—”ë“œë¡œ ì‹¤ì‹œê°„ ì „ì†¡ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
        max_retries = 3
        retry_delay = 0.1  # 100ms
        
        for attempt in range(max_retries):
            try:
                await self.streams_client.send_to_backend_stream({
                    "type": MessageType.ANSWER_CHUNK,
                    "session_id": session_id,
                    "chunk": chunk,
                    "chunk_index": chunk_index,
                    "is_final": False,
                    "timestamp": datetime.now().isoformat()
                })
                # ì²­í¬ ì „ì†¡ ì„±ê³µ - ì¬ì‹œë„í•œ ê²½ìš°ì—ë§Œ ë¡œê¹…
                if attempt > 0:
                    self.logger.info(f"âœ… ì²­í¬ {chunk_index} ì „ì†¡ ì„±ê³µ (ì¬ì‹œë„ {attempt}íšŒ í›„)")
                return
            except Exception as e:
                if attempt < max_retries - 1:
                    await asyncio.sleep(retry_delay * (attempt + 1))  # ì§€ìˆ˜ ë°±ì˜¤í”„
                else:
                    self.logger.error(f"âŒ ì²­í¬ {chunk_index} ì „ì†¡ ìµœì¢… ì‹¤íŒ¨: {e}")
                    # ìµœì¢… ì‹¤íŒ¨ ì‹œì—ë„ ì²­í¬ëŠ” ê±´ë„ˆë›°ì§€ ì•Šê³  ê³„ì† ì§„í–‰
    
    async def _send_final_chunk(self, session_id: int, chunk_count: int):
        """ë§ˆì§€ë§‰ ì²­í¬ ì „ì†¡ (is_final: True)"""
        try:
            await self.streams_client.send_to_backend_stream({
                "type": "answer_chunk",
                "session_id": session_id,
                "chunk": "",  # ë¹ˆ ì²­í¬ë¡œ ì™„ë£Œ ì‹ í˜¸
                "chunk_index": chunk_count + 1,
                "is_final": True,
                "timestamp": datetime.now().isoformat()
            })
            self.logger.info(f"ğŸ“¤ ìµœì¢… ì²­í¬ ì „ì†¡ ì™„ë£Œ: ì„¸ì…˜ {session_id}")
        except Exception as e:
            self.logger.error(f"âŒ ìµœì¢… ì²­í¬ ì „ì†¡ ì‹¤íŒ¨: {e}")
    
    
    async def process_message(self, message_type: str, payload: Dict[str, Any]):
        """ë©”ì‹œì§€ ì²˜ë¦¬ (BaseAgent ë³‘ë ¬ ì²˜ë¦¬ìš©)"""
        try:
            if message_type in ["READY_FOR_ANSWER", "ready_for_answer", "GENERATE_ANSWER", "generate_answer"]:
                await self.process_answer_generation_request(payload)
            else:
                self.logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì‹œì§€ íƒ€ì…: {message_type}")
        except Exception as e:
            self.logger.error(f"ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    
    async def _publish_processing_log(self, session_id: int, stage: str, message: str):
        """ì²˜ë¦¬ ë¡œê·¸ë¥¼ Redisì— ë°œí–‰"""
        try:
            await self.streams_client.send_to_backend_stream({
                "type": "processing_log",
                "agent_name": "AnswerGenerator",
                "session_id": session_id,
                "stage": stage,
                "message": message,
                "timestamp": datetime.now().isoformat()
            })
        except Exception as e:
            self.logger.debug(f"ì²˜ë¦¬ ë¡œê·¸ ë°œí–‰ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
    
    async def process_task(self, task: Task) -> Any:
        """ì‘ì—… ì²˜ë¦¬ (BaseAgent í˜¸í™˜ì„±)"""
        try:
            # Task ê°ì²´ë¥¼ payloadë¡œ ë³€í™˜
            payload = {
                "session_id": task.id,
                "question": task.description,
                "context": task.metadata.get("context", ""),
                "evaluation": task.metadata.get("evaluation", {})
            }
            
            # ê¸°ì¡´ ë‹µë³€ ìƒì„± ë¡œì§ ì‚¬ìš©
            await self.process_answer_generation_request(payload)
            
            return {"success": True, "task_id": task.id}
            
        except Exception as e:
            self.logger.error(f"Task ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return {"success": False, "error": str(e), "task_id": task.id}
    
    
import asyncio
import json
import os
import random
import logging
from datetime import datetime
from typing import Dict, Any, List, Tuple

# ë¡œê¹… ì„¤ì • ì¶”ê°€
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('/app/output/tester.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

try:
    import orjson as jsonlib
except Exception:
    jsonlib = None

import redis.asyncio as redis

# ì„ íƒì  LLM í™œìš©
try:
    from openai import OpenAI  # type: ignore
except Exception:
    OpenAI = None  # type: ignore

QUESTION_SUBMITTED = "question.submitted"
ANSWER_COMPLETED = "answer.completed"
ANSWER_REQUESTED = "answer.requested"

TOPICS = ["ìˆ˜ì—´", "ì í™”ì‹", "ê·€ë‚©ë²•"]

PERSONAS: List[Dict[str, Any]] = [
    {"id": "model_student", "name": "ëª¨ë²”í•™ìƒ", "style": "ì •ì¤‘í•œ ì¡´ëŒ“ë§, êµ°ë”ë”ê¸° ì—†ì´ ëª…í™•í•˜ê²Œ ì§ˆë¬¸. ìˆ˜í•™ê¸°í˜¸/ìš©ì–´ ì •í™•íˆ ì‚¬ìš©. ì´ëª¨ì§€/ì€ì–´ ì—†ìŒ."},
    {"id": "shy_inquisitive", "name": "ì†Œì‹¬í•œ ê¼¬ë¦¬ì§ˆë¬¸ëŸ¬", "style": "ì¡°ì‹¬ìŠ¤ëŸ¬ìš´ ì¡´ëŒ“ë§, ë§ë íë¦¼(â€¦ìš”?), í™•ì‹  ì—†ëŠ” í†¤. ê°„ë‹¨íˆ ì¬í™•ì¸ ì§ˆë¬¸ ìì£¼."},
    {"id": "free_spirited", "name": "ììœ ë¶„ë°©í•œ í•™ìƒ", "style": "ë°˜ë§ ìœ„ì£¼, ê°€ë²¼ìš´ êµ¬ì–´ì²´. ì§§ê²Œ ëŠì–´ ë§í•¨. ì´ëª¨ì§€/ì€ì–´ ê³¼ìš© ê¸ˆì§€."},
    {"id": "curious_gamer", "name": "ê²œì˜ì•Œ í˜¸ê¸°ì‹¬ í•™ìƒ", "style": "ê²Œì„/ë ˆë²¨ ë¹„ìœ  ê°€ë³ê²Œ 1íšŒ ì´í•˜, ì§ˆë¬¸í˜• ëë§ºìŒ. ë°˜ì¡´ëŒ€ í˜¼ìš© ê°€ëŠ¥."},
    {"id": "gamer_kid", "name": "ê²œì˜ì•Œ í•™ìƒ(ì„¸ì»¨)", "style": "ê²Œì„ ì‹œìŠ¤í…œ ë¹„ìœ  1íšŒ ì´í•˜. ë°˜ë§ ìœ„ì£¼, ì¥í™©í•¨ ê¸ˆì§€."},
    {"id": "kpop_fan", "name": "K-POP ë•í›„", "style": "ê°€ë²¼ìš´ íŒ¬ì‹¬ ë¹„ìœ  1íšŒ ì´í•˜. í•µì‹¬ì€ ìˆ˜í•™. ë§íˆ¬ëŠ” ë°ê³  ê²½ì¾Œ."},
    {"id": "sports_captain", "name": "ìš´ë™ë¶€ ì£¼ì¥", "style": "ì§ì„¤ì /ê°„ê²°, ì²´ê° ìœ„ì£¼ í‘œí˜„. ì¡´ëŒ“ë§ ê¸°ë³¸ì´ì§€ë§Œ ë”±ë”±í•˜ì§„ ì•ŠìŒ."},
    {"id": "math_olympiad", "name": "ê²½ì‹œ ì¤€ë¹„ìƒ", "style": "ì •ë°€í•œ ìš©ì–´/ê¸°í˜¸ ì‚¬ìš©, ë°˜ë¡€/ì¡°ê±´ ì§‘ì°©. ì¡´ëŒ“ë§, ë¬¸ì¥ ê¸¸ì–´ë„ ë…¼ë¦¬ì ."},
    {"id": "artsy_poet", "name": "ë¬¸í•™ì  ë¹„ìœ í˜•", "style": "ì§ê´€/ì´ë¯¸ì§€í™” ë¹„ìœ  1íšŒ ì´í•˜. ì˜¨í™”í•œ ë°˜ë§Â·ë°˜ì¡´ëŒ€. í•µì‹¬ ìˆ˜í•™ì€ ì •í™•íˆ."},
    {"id": "meme_speaker", "name": "ë°ˆ ì„ì–´ ë§í•˜ëŠ” í•™ìƒ", "style": "ë¼ì´íŠ¸í•œ ì¸í„°ë„· ë°ˆ 1íšŒ ì´í•˜, ê³¼í•œ ì‹ ì¡°ì–´/ì´ëª¨ì§€ ê¸ˆì§€. ë°˜ë§ ì¤‘ì‹¬."},
    {"id": "busan_dialect", "name": "ë¶€ì‚° ì‚¬íˆ¬ë¦¬ í•™ìƒ", "style": "ê²½ìƒ ë°©ì–¸ ì‚´ì§(ëìŒ ì²˜ë¦¬ ì •ë„). ë°˜ë§. ê³¼ë„í•œ ë°©ì–¸ í‘œí˜„ì€ í”¼í•¨."},
    {"id": "jeolla_dialect", "name": "ì „ë¼ ì‚¬íˆ¬ë¦¬ í•™ìƒ", "style": "ì „ë¼ ë°©ì–¸ í‹° ì‚´ì§, ë¶€ë“œëŸ¬ìš´ ë§íˆ¬. ë°˜ë§ ìœ„ì£¼."},
    {"id": "nocturnal_crammer", "name": "ë°¤ìƒ˜ ë²¼ë½ì¹˜ê¸°", "style": "í”¼ê³¤/ê¸‰í•¨ ë“œëŸ¬ë‚¨. ì§§ê³  ì§ì„¤. ì¡´ëŒ“ë§/ë°˜ë§ ì„ì„."},
    {"id": "pragmatic_skeptic", "name": "í˜„ì‹¤ì ì¸ íšŒì˜ë¡ ì", "style": "íš¨ìœ¨/ì‹œí—˜ ëŒ€ì‘ ìœ„ì£¼ ì§ˆë¬¸. ì¡´ëŒ“ë§, ë‹¨í˜¸í•˜ì§€ë§Œ ì˜ˆì˜ ì§€í‚´."},
    {"id": "anxious_test_taker", "name": "ë¶ˆì•ˆí•œ ìˆ˜í—˜ìƒ", "style": "í™•ì¸ì„± ì§ˆë¬¸ ë§ìŒ. ì¡°ì‹¬ìŠ¤ëŸ° ì¡´ëŒ“ë§, ë§ì¤„ì„í‘œ ê°„ê°„íˆ."},
    {"id": "class_clown", "name": "ë¶„ìœ„ê¸°ë©”ì´ì»¤", "style": "ì¥ë‚œ ì„ì¸ í†¤ 1íšŒ ì´í•˜. í•µì‹¬ì€ ë°”ë¡œ ë¬»ê¸°. ë°˜ë§."},
    {"id": "transfer_student", "name": "ì „í•™ìƒ(ì˜ë‹¨ì–´ ì„ì„)", "style": "ê°„ë‹¨í•œ ì˜ì–´ ë‹¨ì–´ 1íšŒ ì´í•˜ í˜¼ìš©. ì¡´ëŒ“ë§/ë°˜ë§ í˜¼ì¬ ê°€ëŠ¥. ê³¼í•œ ì½©ê¸€ë¦¬ì‹œ ê¸ˆì§€."},
    {"id": "science_nerd", "name": "ê³¼í•™ë•í›„", "style": "ë¬¼ë¦¬/ì»´í“¨í„° ë¹„ìœ  1íšŒ ì´í•˜. ë…¼ë¦¬ ì •ì—°, ì¡´ëŒ“ë§."},
    {"id": "humanities_leaning", "name": "ë¬¸ê³¼í†¤ ìˆ˜í¬ì", "style": "ì§ê´€/ì˜ˆì‹œ ìœ„ì£¼. ì‰¬ìš´ í‘œí˜„ ì„ í˜¸, ì¡´ëŒ“ë§. ìê¸°ë¹„í•˜ ê¸ˆì§€."},
    {"id": "perfectionist", "name": "ì™„ë²½ì£¼ì˜ì", "style": "ì •ì˜/ì¡°ê±´/ë°˜ë¡€ ëê¹Œì§€ í™•ì¸. ì¡´ëŒ“ë§, ë¬¸ì¥ ê¸¸ì–´ì§€ì§€ë§Œ ì •ë¦¬í•´ì„œ ë¬»ê¸°."},
    {"id": "slangy_hothead", "name": "ê±°ì¹œ ë§íˆ¬(ë¼ì´íŠ¸ ìš• í—ˆìš©)", "style": "ë°˜ë§, ê°€ë²¼ìš´ ë¹„ì†ì–´ 0~1íšŒ í—ˆìš©(ì˜ˆ: â€˜ê°œì–´ë µë‹¤â€™, â€˜ë¹¡ì„¸ë‹¤â€™). ì¸ì‹ ê³µê²©/í˜ì˜¤ ê¸ˆì§€. ê³¼í•œ ìš•ì„¤ ê¸ˆì§€."},
    {"id": "tilted_gamer", "name": "ë­í¬ ê¸° tilted ê²Œì´ë¨¸", "style": "ë°˜ë§, ë°°ë°° ê¼¬ì¸ í†¤. ë¼ì´íŠ¸ ìš• 0~1íšŒ(ì˜ˆ: â€˜í˜„íƒ€ ì˜¨ë‹¤â€™, â€˜ë©˜ë¶•â€™). ê³µê²©ì  í‘œí˜„ ê¸ˆì§€."},
    {"id": "absurdist_daydreamer", "name": "ì—‰ëš±í•œ ëª½ìƒê°€", "style": "ëœ¬ê¸ˆì—†ëŠ” ìƒìƒ ë¹„ìœ  1íšŒ ì´í•˜ í›„ ë°”ë¡œ í•µì‹¬ìœ¼ë¡œ ë³µê·€. ë§íˆ¬ëŠ” ë¶€ë“œëŸ¬ìš´ ë°˜ë§. ë¶ˆí•„ìš”í•œ ì¥ë¬¸ ê¸ˆì§€."},
    {"id": "nonsense_jester", "name": "ë“œë¦½ì¹˜ëŠ” ì–´ìˆ˜ì„ ì´", "style": "ê°€ë²¼ìš´ ë“œë¦½/ë§ì¥ë‚œ 1íšŒ ì´í•˜. ì˜ë¯¸ ì—†ìœ¼ë©´ ê³§ì¥ ë³¸ë¡ . ê³¼í•œ ë°ˆ/ì´ëª¨ì§€ ê¸ˆì§€."},
    {"id": "self_deprecating_soft", "name": "ê°€ë²¼ìš´ ìì¡°í˜•", "style": "ì†Œì‹¬í•œ ì¡´ëŒ“ë§. ê°€ë²¼ìš´ ìì¡° 0~1íšŒ í—ˆìš©(ì‹¬í•œ ìê¸°ë¹„í•˜Â·ìí•´ ì•”ì‹œ ê¸ˆì§€). ë§ˆì§€ë§‰ì—” ìš”ì  ì§ˆë¬¸."},
    {"id": "imposter_vibes", "name": "ìì‹ ê° ë¶€ì¡±í˜•", "style": "í™•ì¸ì„± ì§ˆë¬¸ ì¦ìŒ. â€˜ì œê°€ ë†“ì¹œ ê±¸ê¹Œìš”?â€™ ê°™ì€ í‘œí˜„ ì‚¬ìš©. ê³µì†í•œ ì¡´ëŒ“ë§, ì¥í™©í•¨ ì§€ì–‘."},
    {"id": "irritated_shortfuse", "name": "ì‰½ê²Œ ì§œì¦ë‚´ëŠ” ë‹¨ë‹µí˜•", "style": "ì§§ê³  í‰ëª…. êµ°ë”ë”ê¸° ì—†ì´ í•µì‹¬ë§Œ ë¬»ê¸°. ë¹„ì†ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ. ì´ëª¨ì§€/ë°ˆ ê¸ˆì§€."},
    {"id": "angry_time_crunched", "name": "ì‹œê°„ì••ë°• ë°›ëŠ” ë²„ëŸ­í˜•", "style": "ì´ˆì¡°/ì§œì¦ ë“œëŸ¬ë‚¨. ë¼ì´íŠ¸ ë¹„ì†ì–´ 0~1íšŒ í—ˆìš©(ì˜ˆ: â€˜ë¹¡ì„¸ë‹¤â€™). ì¸ì‹ ê³µê²©/í˜ì˜¤ ê¸ˆì§€. ì§§ê³  ì§ì„¤."},
    {"id": "contrarian_debater", "name": "ë”´ì§€ê±°ëŠ” í† ë¡ ëŸ¬", "style": "ë°˜ë¬¸/ë°˜ë¡€ë¡œ ì‹œì‘. ì •ì¤‘í•˜ì§€ë§Œ ë‚ ì¹´ë¡­ê²Œ ë…¼ì  í™•ì¸. ë¶ˆí•„ìš”í•œ ê³µê²©ì  í‘œí˜„ ê¸ˆì§€."},
    {"id": "sarcastic_dry", "name": "ê±´ì¡°í•œ ëƒ‰ì†Œê°€", "style": "ê±´ì¡°í•œ ë¹„ê¼¼ 0~1íšŒ í—ˆìš©. ëª¨ìš•/ì¡°ë¡± ê¸ˆì§€. í•µì‹¬ì€ ëª…í™•íˆ ì§ˆë¬¸."},
    {"id": "scatter_brained", "name": "ì‚°ë§Œí•œ TMIí˜•", "style": "ë§¥ë½ íŠ 1íšŒê¹Œì§€ í—ˆìš© í›„ â€˜ìš”ì â€™ í•œ ì¤„ë¡œ ì •ë¦¬ ìš”ì²­. ë°˜ë§ ìœ„ì£¼, ì¥í™©í•¨ ê¸ˆì§€."},
    {"id": "whiny_but_curious", "name": "ì§•ì§•ëŒ€ëŠ” í˜¸ê¸°ì‹¬í˜•", "style": "ê°€ë²¼ìš´ í‘¸ë… 0~1íšŒ, ê²°êµ­ í˜¸ê¸°ì‹¬ìœ¼ë¡œ ìš”ì  ë¬»ê¸°. ë°˜ì¡´ëŒ€ í˜¼ìš© ê°€ëŠ¥. ê³¼í•œ ë¶ˆí‰ ê¸ˆì§€."},
]

LEVELS: List[Dict[str, Any]] = [
    {
        "id": "naive",
        "name": "ì™„ì „ ê¸°ì´ˆ",
        "style": "ì•„ì£¼ ê¸°ì´ˆ ê°œë…ë¶€í„° ë¬»ëŠ” í†¤, ì •ì˜/ì˜ë¯¸ ìœ„ì£¼, í•œë‘ ë¬¸ì¥",
        "prompt": "ê°€ì¥ ê¸°ì´ˆì ì¸ ì •ì˜ë‚˜ ê°œë…ì„ ë¬»ê³ , ì™œ ê·¸ëŸ°ì§€ ê°„ë‹¨íˆ í™•ì¸í•˜ë ¤ëŠ” í†¤ìœ¼ë¡œ 1~2ë¬¸ì¥ìœ¼ë¡œ í‘œí˜„.",
    },
    {
        "id": "basic",
        "name": "ê¸°ì´ˆ ì‘ìš©",
        "style": "ì‰¬ìš´ ì˜ˆì‹œë¥¼ ì›í•˜ê³ , ì‹œí—˜ì—ì„œ ë°”ë¡œ ì“°ëŠ” ìš”ë ¹ ì„ í˜¸",
        "prompt": "ê°„ë‹¨í•œ ì˜ˆì‹œë‚˜ ì§ê´€ì  ì„¤ëª…ì„ ìš”ì²­. ì‹œí—˜ì—ì„œ ë°”ë¡œ ì“°ëŠ” íŒ/ìš”ë ¹ì„ í•œ ì¤„ë¡œ ë¬¼ì–´ë³´ê¸°.",
    },
    {
        "id": "intermediate",
        "name": "ì¤‘ê°„ ë‚œì´ë„",
        "style": "í•µì‹¬ ì›ë¦¬ë‚˜ ì¼ë°˜í•­/ì¦ëª… ì•„ì´ë””ì–´ë¥¼ í•¨ê»˜ ë¬»ëŠ” í†¤",
        "prompt": "ê°œë… ì´í•´ì™€ í•¨ê»˜ ì¼ë°˜í•­/ê·€ë‚© ì•„ì´ë””ì–´ ë“± í•µì‹¬ ì›ë¦¬ë¥¼ ê°„ë‹¨íˆ í™•ì¸í•˜ëŠ” ì‹ìœ¼ë¡œ 1~2ë¬¸ì¥.",
    },
    {
        "id": "advanced",
        "name": "ì‹¬í™”",
        "style": "ì¡°ê±´/ì˜ˆì™¸/ë°˜ë¡€ ê°€ëŠ¥ì„±ê¹Œì§€ ì§šëŠ” ë¶„ì„ì  í†¤",
        "prompt": "ì¡°ê±´ê³¼ ì˜ˆì™¸, ë°˜ë¡€ ê°€ëŠ¥ì„±, ê²½ê³„ ìƒí™©ì„ ì§šì–´ë³´ëŠ” ì‹¬í™” ì§ˆë¬¸ìœ¼ë¡œ 1~2ë¬¸ì¥. ì§€ë‚˜ì¹œ ì¥ë¬¸ ê¸ˆì§€.",
    },
    {
        "id": "olympiad",
        "name": "ê²½ì‹œ/ì¦ëª…",
        "style": "ì¦ëª… ê´€ì , ì—„ë°€/ê°„ê²°, í•µì‹¬ ì¡°ê±´ ì •ë¦¬",
        "prompt": "ì¦ëª… ê´€ì ì—ì„œ í•µì‹¬ ì¡°ê±´ê³¼ êµ¬ì¡°ë¥¼ ë¬¼ìœ¼ë©°, í•„ìš”ì‹œ ë°˜ë¡€/ê²½ê³„ë„ í•œ ì¤„ë¡œ ìš”ì²­. 1~2ë¬¸ì¥.",
    },
]

def _parse_level_weights(spec: str) -> Dict[str, float]:
    default = {"naive": 0.2, "basic": 0.3, "intermediate": 0.25, "advanced": 0.2, "olympiad": 0.05}
    try:
        if not spec:
            return default
        parts = [p.strip() for p in spec.split(",") if p.strip()]
        weights: Dict[str, float] = {}
        for part in parts:
            if ":" not in part:
                continue
            k, v = part.split(":", 1)
            k = k.strip()
            w = float(v.strip())
            if k:
                weights[k] = max(0.0, w)
        total = sum(weights.values())
        if total <= 0:
            return default
        # normalize
        for k in list(weights.keys()):
            weights[k] = weights[k] / total
        # ensure all ids exist at least with tiny weight for stability
        ids = {lvl["id"] for lvl in LEVELS}
        for i in ids:
            weights.setdefault(i, 0.0)
        return weights
    except Exception:
        return default

def _sample_level(weights: Dict[str, float]) -> Dict[str, Any]:
    try:
        r = random.random()
        cum = 0.0
        by_id = {lvl["id"]: lvl for lvl in LEVELS}
        for lvl_id, w in weights.items():
            cum += w
            if r <= cum:
                return by_id.get(lvl_id, LEVELS[0])
        # fallback
        return LEVELS[-1]
    except Exception:
        return LEVELS[0]

SAMPLE_UTTER_TEMPLATES = [
    "{persona} í†¤ìœ¼ë¡œ [{topic}] ê´€ë ¨í•´ì„œ ì´ëŸ° ëŠë‚Œìœ¼ë¡œ ë¬¼ì–´ë³¼ë˜ìš”: {utter}",
]

SEED_UTTERS = {
    "ìˆ˜ì—´": [
        "ë“±ì°¨ìˆ˜ì—´ì´ë‘ ë“±ë¹„ìˆ˜ì—´ êµ¬ë¶„í•  ë•Œ, ì´ˆí•­/ê³µì°¨ë§Œ ë³´ë©´ ë˜ëŠ” ê±° ë§ì£ ?",
        "ìˆ˜ì—´ a_nì´ 2n+1ì´ë©´, nì´ ì»¤ì§ˆìˆ˜ë¡ ëŒ€ì¶© ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ ê°ì´ ì•ˆ ì™€ìš”.",
        "ìˆ˜ì—´ ê·¸ë˜í”„ ê·¸ë ¤ë³´ë©´ ë” ë¹ ë¥´ê²Œ ì´í•´í•  ìˆ˜ ìˆëŠ” í¬ì¸íŠ¸ê°€ ë­ì˜ˆìš”?",
    ],
    "ì í™”ì‹": [
        "a_{n+1} = 2a_n + 1 ì´ëŸ° ê±° í’€ ë•Œ, ì¼ë°˜í•­ ë°”ë¡œ ì°¾ëŠ” íŒ ìˆë‚˜ìš”?",
        "í”¼ë³´ë‚˜ì¹˜ ì í™”ì‹ì´ë‘ ë¹„ìŠ·í•œ ë¬¸ì œ ë§Œë“¤ ìˆ˜ ìˆì–´ìš”? ë‚œì´ë„ ì¤‘ê°„ìœ¼ë¡œ!",
        "ì í™”ì‹ì—ì„œ ì´ˆê¸°ê°’ì´ ì™œ ê·¸ë ‡ê²Œ ì¤‘ìš”í•œì§€ ì˜ˆì‹œë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
    ],
    "ê·€ë‚©ë²•": [
        "ìˆ˜í•™ì  ê·€ë‚©ë²•ìœ¼ë¡œ n^2 - nì´ í•­ìƒ ì§ìˆ˜ë¼ëŠ” ê±¸ ì‰½ê²Œ ë³´ì—¬ì¤„ ìˆ˜ ìˆë‚˜ìš”?",
        "ê·€ë‚© ê°€ì •ì—ì„œ ìê¾¸ ë§‰íˆëŠ”ë°, ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ëŠ” ì—°ê²° ê³ ë¦¬ê°€ í—·ê°ˆë ¤ìš”.",
        "ê·€ë‚©ë²•ìœ¼ë¡œ ì¦ëª…í•˜ë©´ ì§ê´€ì´ ë” ìƒê¸°ë‚˜ìš”, ì•„ë‹ˆë©´ ê·¸ëƒ¥ í˜•ì‹ì ì¸ê°€ìš”?",
    ],
}


MISTAKE_MAP = [
    ("ë“±ì°¨ìˆ˜ì—´", "ë“±ë¹„ìˆ˜ì—´"),
    ("ë“±ë¹„ìˆ˜ì—´", "ë“±ì°¨ìˆ˜ì—´"),
    ("ì í™”ì‹", "ì •í™”ì‹"),
    ("ê·€ë‚©ë²•", "ê·€ë‚¨ë²•"),
    ("ì¼ë°˜í•­", "ì¼ë°©í•­"),
    ("ê·€ë‚© ê°€ì •", "ê·€ë‚© ê³¼ì •"),
    ("ê³µì°¨", "ê³µì¹˜"),
    ("ê³µë¹„", "ê³µí”¼"),
]


def _fast_json_loads(line: str) -> Any:
    if jsonlib is not None:
        try:
            return jsonlib.loads(line)
        except Exception:
            return None
    try:
        return json.loads(line)
    except Exception:
        return None


def load_questions_from_dataset(path: str, max_items: int = 2000) -> List[str]:
    questions: List[str] = []
    if not path or not os.path.exists(path):
        return questions
    try:
        with open(path, "r", encoding="utf-8") as f:
            for idx, line in enumerate(f):
                if idx >= max_items:
                    break
                obj = _fast_json_loads(line)
                if not isinstance(obj, dict):
                    continue
                for key in ("question", "query", "utterance", "student_question", "content", "text"):
                    val = obj.get(key)
                    if isinstance(val, str) and 5 <= len(val) <= 500:
                        questions.append(val.strip())
                        break
    except Exception:
        pass
    return questions


def inject_mistake(text: str, probability: float) -> Tuple[str, Dict[str, Any]]:
    """í…ìŠ¤íŠ¸ì— ê²½ë¯¸í•œ ë§ì‹¤ìˆ˜ë¥¼ 0~1íšŒ ì£¼ì…í•˜ê³  ë©”íƒ€ë°ì´í„°ë¥¼ í•¨ê»˜ ë°˜í™˜"""
    meta: Dict[str, Any] = {"applied": False}
    try:
        if random.random() >= probability:
            return text, meta
        candidates = [pair for pair in MISTAKE_MAP if pair[0] in text]
        pair = random.choice(candidates) if candidates else random.choice(MISTAKE_MAP)
        new_text = text.replace(pair[0], pair[1], 1)
        meta = {"applied": True, "from": pair[0], "to": pair[1]}
        return new_text, meta
    except Exception:
        return text, meta


def llm_paraphrase(base: str, persona: Dict[str, Any], topic: str, allow_mistakes: bool, style_intensity: float, level: Dict[str, Any]) -> str:
    if OpenAI is None or not os.getenv("OPENAI_API_KEY"):
        return base
    try:
        client = OpenAI()
        sys_prompt = (
            "ë„ˆëŠ” í•œêµ­ì˜ 10ëŒ€ í•™ìƒì²˜ëŸ¼ ë§í•˜ëŠ” ìŠ¤íƒ€ì¼ëŸ¬ì•¼. ì£¼ì–´ì§„ ë¬¸ì¥ì„ ë” ìì—°ìŠ¤ëŸ½ê³  ì‹¤ì œ í•™ìƒ ê°™ê²Œ 1~2ë¬¸ì¥ìœ¼ë¡œ ë°”ê¿”. "
            "ë¬¸ì¥ì€ ì›¹ UIì— ê³§ë°”ë¡œ ë…¸ì¶œë  ìˆ˜ ìˆìœ¼ë‹ˆ ê°„ê²°í•˜ê³  ë§íˆ¬ ì¤‘ì‹¬ìœ¼ë¡œ. ê³¼ì¥ëœ ì´ëª¨ì§€/ì€ì–´ëŠ” ê¸ˆì§€."
        )
        user_prompt = (
            f"í˜ë¥´ì†Œë‚˜: {persona['name']} ({persona['style']})\n"
            f"ì£¼ì œ: {topic} (ìˆ˜ì—´/ì í™”ì‹/ê·€ë‚©ë²• ë²”ìœ„)\n"
            f"ë¬¸ì¥: {base}\n"
            f"ìŠ¤íƒ€ì¼ ê°•ë„: {style_intensity:.1f}\n"
            f"ìˆ˜ì¤€: {level['name']} ({level['style']})\n"
            f"ìˆ˜ì¤€ ì§€ì¹¨: {level['prompt']}\n"
            f"ë§ì‹¤ìˆ˜ í—ˆìš©: {'ì•½ê°„' if allow_mistakes else 'ë¶ˆê°€'}\n"
            "ìš”êµ¬ì‚¬í•­:\n"
            "- í•™ìƒ ë§íˆ¬ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì¬ì‘ì„± (1~2ë¬¸ì¥).\n"
            "- ìˆ˜í•™ ìš©ì–´/í‘œí˜„ì€ ëŒ€ì²´ë¡œ ìœ ì§€í•˜ë˜, í—ˆìš© ì‹œ ì•„ì£¼ ê°€ë²¼ìš´ ì‹¤ìˆ˜(ìš©ì–´ ì‚´ì§ í—·ê°ˆë¦¼/ì˜¤íƒ€) 0~1íšŒë§Œ.\n"
            "- ë”°ì˜´í‘œ/ë¨¸ë¦¬ë§/ë¶ˆí•„ìš”í•œ ì„¤ëª… ì—†ì´ ê²°ê³¼ ë¬¸ì¥ë§Œ ì¶œë ¥."
        )
        resp = client.chat.completions.create(
            model=os.getenv("STUDENT_AGENT_MODEL", "gpt-4o-mini"),
            max_completion_tokens=120,
            messages=[
                {"role": "system", "content": sys_prompt},
                {"role": "user", "content": user_prompt},
            ],
        )
        out = (resp.choices[0].message.content or base).strip()
        return out
    except Exception:
        return base

def adjust_by_level(base: str, level_id: str, topic: str) -> str:
    try:
        if level_id == "naive":
            return f"{base} ì´ê±° ê¸°ì´ˆë¶€í„° ì‰½ê²Œ ì„¤ëª…í•´ì¤„ ìˆ˜ ìˆì–´ìš”?"
        if level_id == "basic":
            return f"{base} ê°„ë‹¨í•œ ì˜ˆì‹œë¡œ ë°”ë¡œ ì´í•´í•  ìˆ˜ ìˆê²Œ ì•Œë ¤ì£¼ì„¸ìš”."
        if level_id == "intermediate":
            return f"{base} ì›ë¦¬ë‚˜ ì¼ë°˜í•­ ì•„ì´ë””ì–´ë„ í•¨ê»˜ ì„¤ëª… ê°€ëŠ¥í• ê¹Œìš”?"
        if level_id == "advanced":
            return f"{base} ì¡°ê±´/ì˜ˆì™¸ë‚˜ ë°˜ë¡€ ê°€ëŠ¥ì„±ê¹Œì§€ ì§šì–´ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?"
        if level_id == "olympiad":
            return f"{base} ì¦ëª… ê´€ì ì—ì„œ í•µì‹¬ ì¡°ê±´ê³¼ ê²½ê³„ ê²½ìš°ê¹Œì§€ ê°„ê²°íˆ ë¶€íƒë“œë ¤ìš”."
        return base
    except Exception:
        return base


async def publish(client: redis.Redis, channel: str, payload: Dict[str, Any]) -> None:
    data = json.dumps(payload, ensure_ascii=False)
    await client.publish(channel, data)


def _append_jsonl(path: str, obj: Dict[str, Any]) -> None:
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "a", encoding="utf-8") as f:
        f.write(json.dumps(obj, ensure_ascii=False) + "\n")


def _update_summary(path: str, persona_id: str, topic: str, mistake_meta: Dict[str, Any]) -> None:
    try:
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                summary = json.load(f)
        else:
            summary = {"total": 0, "by_persona": {}, "by_topic": {}, "mistakes": {"applied": 0, "by_pair": {}}}
        summary["total"] = int(summary.get("total", 0)) + 1
        byp = summary.setdefault("by_persona", {})
        byp[persona_id] = int(byp.get(persona_id, 0)) + 1
        byt = summary.setdefault("by_topic", {})
        byt[topic] = int(byt.get(topic, 0)) + 1
        if mistake_meta.get("applied"):
            mist = summary.setdefault("mistakes", {"applied": 0, "by_pair": {}})
            mist["applied"] = int(mist.get("applied", 0)) + 1
            pair_key = f"{mistake_meta.get('from','')}->{mistake_meta.get('to','')}"
            mist.setdefault("by_pair", {})
            mist["by_pair"][pair_key] = int(mist["by_pair"].get(pair_key, 0)) + 1
        summary["updated_at"] = datetime.utcnow().isoformat()
        with open(path, "w", encoding="utf-8") as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
    except Exception:
        pass


async def run_student_agent():
    redis_url = os.getenv("REDIS_URL", "redis://localhost:6379")
    personas_env = os.getenv("PERSONAS", "all")
    num_samples = int(os.getenv("NUM_SAMPLES", "5"))
    output_dir = os.getenv("OUTPUT_DIR", "/app/output")
    dataset_path = os.getenv("DATASET_PATH", "")
    paraphrase_with_llm = os.getenv("PARAPHRASE_WITH_LLM", "0") == "1"
    mistake_prob = float(os.getenv("MISTAKE_PROB", "0.3"))
    style_intensity = float(os.getenv("STYLE_INTENSITY", "0.7"))
    clarify_loop = os.getenv("CLARIFY_LOOP", "1") == "1"
    clarify_mode = os.getenv("CLARIFY_MODE", "augment")  # augment | rewrite
    clarify_max_rounds = int(os.getenv("CLARIFY_MAX_ROUNDS", "1"))
    level_weights = _parse_level_weights(os.getenv("LEVEL_WEIGHTS", ""))

    logger.info(f"ğŸš€ Tester ì‹œì‘ - Redis: {redis_url}, ìƒ˜í”Œ ìˆ˜: {num_samples}, í˜ë¥´ì†Œë‚˜: {personas_env}")
    logger.info(f"ğŸ“Š ì„¤ì • - ë§ì‹¤ìˆ˜ í™•ë¥ : {mistake_prob}, ìŠ¤íƒ€ì¼ ê°•ë„: {style_intensity}, ëª…ë£Œí™” ë£¨í”„: {clarify_loop}")

    client = redis.from_url(redis_url)
    await client.ping()
    logger.info("âœ… Redis ì—°ê²° ì„±ê³µ")

    if personas_env == "all":
        personas = PERSONAS
    else:
        ids = [p.strip() for p in personas_env.split(",") if p.strip()]
        personas = [p for p in PERSONAS if p["id"] in ids] or PERSONAS

    logger.info(f"ğŸ‘¥ ì‚¬ìš© í˜ë¥´ì†Œë‚˜: {len(personas)}ê°œ - {[p['name'] for p in personas[:3]]}{'...' if len(personas) > 3 else ''}")
    logger.info(f"ğŸ“š ë ˆë²¨ ê°€ì¤‘ì¹˜: {level_weights}")

    dataset_questions = load_questions_from_dataset(dataset_path, max_items=5000)
    logger.info(f"ğŸ“– ë°ì´í„°ì…‹ ì§ˆë¬¸: {len(dataset_questions)}ê°œ ë¡œë“œë¨")

    os.makedirs(output_dir, exist_ok=True)
    run_ts = int(datetime.utcnow().timestamp())
    dialogue_id = f"d{run_ts}"
    dialogue_path = os.path.join(output_dir, f"student_dialog_{run_ts}.jsonl")
    conv_path = os.path.join(output_dir, "conversations", f"{dialogue_id}.jsonl")
    summary_path = os.path.join(output_dir, "summary.json")

    async with client.pubsub() as sub:
        await sub.subscribe(ANSWER_COMPLETED)

        async def wait_answer(request_id: str, timeout: float = 120.0) -> Dict[str, Any]:
            """answer.completed ì „ì—­ ì±„ë„ê³¼ per-request ì±„ë„ì„ ë™ì‹œì— ì²­ì·¨í•˜ì—¬ ìœ ì‹¤ì„ ì¤„ì„"""
            start = datetime.utcnow()
            last_payload: Dict[str, Any] = {}
            per_request_channel = f"{ANSWER_COMPLETED}:{request_id}"
            # per-request ì±„ë„ ì¶”ê°€ êµ¬ë… (ì´ë¯¸ êµ¬ë…ë˜ì–´ ìˆì–´ë„ ì•ˆì „)
            try:
                await sub.subscribe(per_request_channel)
            except Exception:
                pass
            try:
                while (datetime.utcnow() - start).total_seconds() < timeout:
                    msg = await sub.get_message(ignore_subscribe_messages=True, timeout=1.0)
                    if not msg or msg.get("type") != "message":
                        await asyncio.sleep(0.1)
                        continue
                    try:
                        data = msg.get("data")
                        payload = json.loads(data.decode("utf-8") if isinstance(data, (bytes, bytearray)) else data)
                    except Exception:
                        continue
                    # per-request ì±„ë„ ë˜ëŠ” í˜ì´ë¡œë“œì˜ request_id ë§¤ì¹­
                    ch = msg.get("channel")
                    ch = ch.decode("utf-8") if isinstance(ch, (bytes, bytearray)) else ch
                    if ch == per_request_channel or payload.get("request_id") == request_id:
                        meta = (payload.get("metadata") or {})
                        if meta.get("type") == "answer":
                            return payload
                        last_payload = payload
                return last_payload
            finally:
                try:
                    await sub.unsubscribe(per_request_channel)
                except Exception:
                    pass

        def refine_question(original: str, clarification_text: str) -> str:
            """clarificationì„ ë°˜ì˜í•´ ì§ˆë¬¸ì„ ë³´ê°•/ì¬ì‘ì„±"""
            if clarify_mode == "rewrite" and OpenAI and os.getenv("OPENAI_API_KEY"):
                try:
                    client = OpenAI()
                    sys = "í•™ìƒ ì§ˆë¬¸ì„ ë” ëª…í™•í•˜ê²Œ í•œ ë¬¸ì¥ìœ¼ë¡œ ì¬ì‘ì„±. ì§ˆë¬¸ì„ ë°˜ë³µ ì„¤ëª…í•˜ì§€ ë§ê³ , í•„ìš”í•œ ì •ë³´(ì¡°ê±´/ëª©í‘œ/ì¶œë ¥í˜•ì‹)ë¥¼ í¬í•¨."
                    user = (
                        f"ì›ë¬¸: {original}\nëª…ë£Œí™” í”¼ë“œë°±: {clarification_text}\n"
                        "í•œ ë¬¸ì¥ìœ¼ë¡œ ì¬ì‘ì„±. ë¶ˆí•„ìš”í•œ ì¸ì‚¬/ë¨¸ë¦¬ë§ ê¸ˆì§€."
                    )
                    resp = client.chat.completions.create(
                        model=os.getenv("STUDENT_AGENT_MODEL", "gpt-5-mini"),
                        max_completion_tokens=120,
                        messages=[{"role": "system", "content": sys}, {"role": "user", "content": user}],
                    )
                    out = (resp.choices[0].message.content or original).strip()
                    return out
                except Exception:
                    pass
            # ê¸°ë³¸ ë³´ê°•(augment): ì¡°ê±´/ìš”êµ¬ì‚¬í•­ì„ ë§ë¶™ì—¬ í•œ ë¬¸ì¥ ê°•í™”
            safe_text = (clarification_text or "").strip()
            first_line = safe_text.splitlines()[0] if safe_text.splitlines() else ""
            clipped = first_line[:160]
            if clipped:
                return f"{original} (ì¶”ê°€ ì¡°ê±´: {clipped})"
            return original

        samples = 0
        logger.info(f"ğŸ”„ í…ŒìŠ¤íŠ¸ ì‹œì‘ - ì´ {num_samples}ê°œ ìƒ˜í”Œ")
        with open(dialogue_path, "a", encoding="utf-8") as f:
            while samples < num_samples:
                persona = random.choice(personas)
                level = _sample_level(level_weights)
                if dataset_questions:
                    base_q = random.choice(dataset_questions)
                    topic = next((t for t in TOPICS if t in base_q), random.choice(TOPICS))
                    utter = base_q
                else:
                    topic = random.choice(TOPICS)
                    utter = random.choice(SEED_UTTERS[topic])

                logger.info(f"ğŸ“ ìƒ˜í”Œ {samples + 1}/{num_samples} - í˜ë¥´ì†Œë‚˜: {persona['name']}, ë ˆë²¨: {level['name']}, ì£¼ì œ: {topic}")
                logger.info(f"ğŸ’¬ ì›ë³¸ ì§ˆë¬¸: {utter[:100]}{'...' if len(utter) > 100 else ''}")

                # í˜ë¥´ì†Œë‚˜ ìŠ¤íƒ€ì¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì¬ì‘ì„± + ë§ì‹¤ìˆ˜ ì£¼ì…
                transformed = utter
                if paraphrase_with_llm:
                    logger.info("ğŸ¤– LLMì„ ì‚¬ìš©í•œ ì§ˆë¬¸ ë³€í™˜ ì‹œì‘")
                    transformed = llm_paraphrase(utter, persona, topic, allow_mistakes=True, style_intensity=style_intensity, level=level)
                    logger.info(f"ğŸ¤– LLM ë³€í™˜ ê²°ê³¼: {transformed[:100]}{'...' if len(transformed) > 100 else ''}")
                else:
                    logger.info("ğŸ“ ê¸°ë³¸ ë ˆë²¨ ì¡°ì • ì‚¬ìš©")
                    transformed = adjust_by_level(utter, level.get("id", "basic"), topic)
                    logger.info(f"ğŸ“ ë ˆë²¨ ì¡°ì • ê²°ê³¼: {transformed[:100]}{'...' if len(transformed) > 100 else ''}")
                
                transformed, mistake_meta = inject_mistake(transformed, mistake_prob)
                if mistake_meta.get("applied"):
                    logger.info(f"ğŸ”§ ë§ì‹¤ìˆ˜ ì£¼ì…: '{mistake_meta.get('from')}' â†’ '{mistake_meta.get('to')}'")

                question_text = transformed
                request_id = f"stu_{int(datetime.utcnow().timestamp()*1000)}_{samples}"
                logger.info(f"ğŸ†” ìš”ì²­ ID ìƒì„±: {request_id}")

                record = {
                    "ts": datetime.utcnow().isoformat(),
                    "role": "student",
                    "dialogue_id": dialogue_id,
                    "persona": persona["id"],
                    "level": level["id"],
                    "topic": topic,
                    "request_id": request_id,
                    "utterance": question_text,
                    "paraphrased": paraphrase_with_llm,
                    "style_intensity": style_intensity,
                    "mistake": mistake_meta,
                }
                f.write(json.dumps(record, ensure_ascii=False) + "\n")
                f.flush()

                # ì¶”ê°€ ë¡œê·¸: ëŒ€í™”ë³„/í˜ë¥´ì†Œë‚˜ë³„ íŒŒì¼ì—ë„ ê¸°ë¡
                _append_jsonl(conv_path, record)
                _append_jsonl(os.path.join(output_dir, "persona", persona["id"], "dialogue.jsonl"), record)
                _update_summary(summary_path, persona["id"], topic, mistake_meta)

                logger.info(f"ğŸ“¤ Redisë¡œ ì§ˆë¬¸ ì „ì†¡: {QUESTION_SUBMITTED}")
                logger.info(f"ğŸ“‹ ì „ì†¡ ë‚´ìš©: {question_text[:100]}{'...' if len(question_text) > 100 else ''}")
                
                await publish(client, QUESTION_SUBMITTED, {
                    "request_id": request_id,
                    "question": question_text,
                    "context": {
                        "topic": topic,
                        "ui_hint": "ì›¹ ì¸í„°í˜ì´ìŠ¤ ì¶œë ¥ìš© ë¬¸ì¥ ì¤‘ì‹¬",
                    },
                })
                logger.info("âœ… ì§ˆë¬¸ ì „ì†¡ ì™„ë£Œ")

                # clarify â†’ refine â†’ resend ë£¨í”„
                rounds = 0
                current_req = request_id
                logger.info(f"â³ ì‘ë‹µ ëŒ€ê¸° ì‹œì‘: {current_req}")
                response = await wait_answer(current_req)
                logger.info(f"ğŸ“¨ ì‘ë‹µ ìˆ˜ì‹ : {response.get('metadata', {}).get('type', 'unknown') if isinstance(response, dict) else 'unknown'}")
                
                while clarify_loop and rounds < clarify_max_rounds and (response.get("metadata") or {}).get("type") == "clarification":
                    clar_text = response.get("answer", "")
                    logger.info(f"ğŸ” ëª…ë£Œí™” ìš”ì²­ ìˆ˜ì‹  (ë¼ìš´ë“œ {rounds + 1}): {clar_text[:100]}{'...' if len(clar_text) > 100 else ''}")
                    
                    refined = refine_question(question_text, clar_text)
                    logger.info(f"âœï¸ ì§ˆë¬¸ ê°œì„ : {refined[:100]}{'...' if len(refined) > 100 else ''}")
                    
                    # ë¡œê·¸ ê¸°ë¡(clarification ìˆ˜ì‹ )
                    clar_rec = {
                        "ts": datetime.utcnow().isoformat(),
                        "role": "agent",
                        "dialogue_id": dialogue_id,
                        "request_id": current_req,
                        "response": response,
                        "clarification": True,
                    }
                    f.write(json.dumps(clar_rec, ensure_ascii=False) + "\n")
                    f.flush()
                    _append_jsonl(conv_path, clar_rec)
                    _append_jsonl(os.path.join(output_dir, "persona", persona["id"], "dialogue.jsonl"), clar_rec)

                    # ì¬ì „ì†¡
                    rounds += 1
                    question_text = refined
                    current_req = f"{request_id}_r{rounds}"
                    logger.info(f"ğŸ”„ ëª…ë£Œí™” í›„ ì¬ì „ì†¡ (ë¼ìš´ë“œ {rounds}): {current_req}")
                    
                    resend_rec = {
                        "ts": datetime.utcnow().isoformat(),
                        "role": "student",
                        "dialogue_id": dialogue_id,
                        "persona": persona["id"],
                        "level": level["id"],
                        "topic": topic,
                        "request_id": current_req,
                        "utterance": question_text,
                        "refined_from": request_id,
                        "clarify_round": rounds,
                    }
                    f.write(json.dumps(resend_rec, ensure_ascii=False) + "\n")
                    f.flush()
                    _append_jsonl(conv_path, resend_rec)
                    _append_jsonl(os.path.join(output_dir, "persona", persona["id"], "dialogue.jsonl"), resend_rec)

                    logger.info(f"ğŸ“¤ ê°œì„ ëœ ì§ˆë¬¸ ì¬ì „ì†¡: {current_req}")
                    await publish(client, QUESTION_SUBMITTED, {
                        "request_id": current_req,
                        "question": question_text,
                        "context": {
                            "topic": topic,
                            "ui_hint": "ì›¹ ì¸í„°í˜ì´ìŠ¤ ì¶œë ¥ìš© ë¬¸ì¥ ì¤‘ì‹¬",
                        },
                    })
                    logger.info("âœ… ê°œì„ ëœ ì§ˆë¬¸ ì „ì†¡ ì™„ë£Œ")
                    
                    response = await wait_answer(current_req)
                    logger.info(f"ğŸ“¨ ê°œì„ ëœ ì§ˆë¬¸ ì‘ë‹µ ìˆ˜ì‹ : {response.get('metadata', {}).get('type', 'unknown') if isinstance(response, dict) else 'unknown'}")
                # ëª…ë£Œí™” ë£¨í”„ ì¢…ë£Œ í›„ì—ë„ ìµœì¢… ë‹µë³€ì´ ì—†ìœ¼ë©´(ë˜ëŠ” ë£¨í”„ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©´),
                # í…ŒìŠ¤íŠ¸ í¸ì˜ìƒ í•œ ë²ˆ ê°•ì œë¡œ ë‹µë³€ì„ ìš”ì²­í•´ ê¸°ë¡ì„ ë‚¨ê¸¸ ìˆ˜ ìˆë‹¤.
                force_answer = os.getenv("TEST_FORCE_ANSWER_ON_TIMEOUT", "1") == "1"
                meta_type = (response.get("metadata") or {}).get("type") if isinstance(response, dict) else None
                if force_answer and meta_type != "answer":
                    await publish(client, ANSWER_REQUESTED, {
                        "request_id": current_req,
                        "question": question_text,
                        "context": {"topic": topic, "ui_hint": "í…ŒìŠ¤íŠ¸ ê°•ì œ ë‹µë³€ ìš”ì²­"},
                        "metadata": {"from": "tester", "reason": "force_answer"}
                    })
                    response = await wait_answer(current_req)

                resp_rec = {
                    "ts": datetime.utcnow().isoformat(),
                    "role": "agent",
                    "dialogue_id": dialogue_id,
                    "request_id": current_req,
                    "response": response,
                }
                f.write(json.dumps(resp_rec, ensure_ascii=False) + "\n")
                f.flush()
                _append_jsonl(conv_path, resp_rec)
                _append_jsonl(os.path.join(output_dir, "persona", persona["id"], "dialogue.jsonl"), resp_rec)

                samples += 1
                logger.info(f"âœ… ìƒ˜í”Œ {samples}/{num_samples} ì™„ë£Œ - {persona['name']} ({topic})")
                logger.info(f"ğŸ“Š ì§„í–‰ë¥ : {(samples/num_samples)*100:.1f}%")

    await client.close()
    logger.info("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    logger.info(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_dir}")

if __name__ == "__main__":
    asyncio.run(run_student_agent())

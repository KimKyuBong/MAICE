#!/usr/bin/env python3
"""
ë”¥í˜ì´í¬ì‹ í•™ìƒ ì§ˆë¬¸ ìƒì„±ê¸°
ì‹¤ì œ í•™ìƒë“¤ì´ GPTì— ì§ˆë¬¸í•œ í˜•íƒœë¥¼ ë¶„ì„í•´ì„œ ë¹„ìŠ·í•œ ë¬¸ì²´ì™€ íŒ¨í„´ìœ¼ë¡œ ìƒˆë¡œìš´ ì§ˆë¬¸ì„ ìƒì„±
"""

import json
import os
import random
import re
from typing import Dict, List, Tuple, Optional
from collections import defaultdict
import logging

# .env íŒŒì¼ ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()
    print("âœ… .env íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
except ImportError:
    print("âš ï¸ python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install python-dotenvë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    print("í™˜ê²½ë³€ìˆ˜ë¥¼ ì§ì ‘ ì„¤ì •í•˜ê±°ë‚˜ .env íŒŒì¼ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ë¡œê¹… ì„¤ì •
log_level = os.getenv('LOG_LEVEL', 'INFO')
logging.basicConfig(
    level=getattr(logging, log_level.upper()),
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('deepfake_generator.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class DeepfakeQuestionGenerator:
    """ì‹¤ì œ í•™ìƒ ì§ˆë¬¸ íŒ¨í„´ì„ ë¶„ì„í•˜ê³  ë”¥í˜ì´í¬ì‹ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, data_path: str = None):
        self.data_path = data_path or os.getenv('DATA_PATH', 'data/evaluation_statistics.json')
        self.real_questions = []
        self.question_patterns = defaultdict(list)
        self.style_patterns = defaultdict(list)
        self.topic_keywords = defaultdict(list)
        self.load_real_data()
        self.analyze_patterns()
    
    def load_real_data(self):
        """ì‹¤ì œ í•™ìƒ ì§ˆë¬¸ ë°ì´í„° ë¡œë“œ"""
        try:
            # .envì—ì„œ ì„¤ì •ëœ ê²½ë¡œ ìš°ì„  ì‚¬ìš©
            possible_paths = [
                self.data_path,
                'data/evaluation_statistics.json',
                'tester/data/evaluation_statistics.json',
                '../data/evaluation_statistics.json'
            ]
            
            data = None
            for path in possible_paths:
                if os.path.exists(path):
                    with open(path, "r", encoding="utf-8") as f:
                        data = json.load(f)
                    logging.info(f"âœ… ë°ì´í„° íŒŒì¼ ë¡œë“œ ì„±ê³µ: {path}")
                    break
            
            if not data:
                logging.warning("âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                logging.warning(f"ì‹œë„í•œ ê²½ë¡œë“¤: {possible_paths}")
                return
            
            # ì§ˆë¬¸ë³„_êµì‚¬_í‰ê°€ì—ì„œ ì§ˆë¬¸ ì¶”ì¶œ
            if 'ì§ˆë¬¸ë³„_êµì‚¬_í‰ê°€' in data:
                max_questions = int(os.getenv('MAX_QUESTIONS', 1000))
                question_count = 0
                
                for question_id, question_data in data['ì§ˆë¬¸ë³„_êµì‚¬_í‰ê°€'].items():
                    if question_count >= max_questions:
                        break
                        
                    if isinstance(question_data, dict) and 'ì§ˆë¬¸_ì›ë¬¸' in question_data:
                        question_text = question_data['ì§ˆë¬¸_ì›ë¬¸']
                        if isinstance(question_text, str) and 5 <= len(question_text) <= 500:
                            self.real_questions.append(question_text.strip())
                            question_count += 1
            
            logging.info(f"ë¡œë“œëœ ì‹¤ì œ ì§ˆë¬¸ ìˆ˜: {len(self.real_questions)} (ìµœëŒ€: {max_questions})")
            
        except Exception as e:
            logging.error(f"ì‹¤ì œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            logging.error("ë°ì´í„° íŒŒì¼ ê²½ë¡œì™€ í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”")
    
    def analyze_patterns(self):
        """ì§ˆë¬¸ íŒ¨í„´ ë¶„ì„"""
        if not self.real_questions:
            logging.warning("ë¶„ì„í•  ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤")
            return
        
        for question in self.real_questions:
            # ë¬¸ì²´ íŒ¨í„´ ë¶„ì„
            self._analyze_style_patterns(question)
            
            # ì£¼ì œë³„ í‚¤ì›Œë“œ ì¶”ì¶œ
            self._extract_topic_keywords(question)
            
            # ì§ˆë¬¸ íŒ¨í„´ ë¶„ë¥˜
            self._categorize_question_patterns(question)
        
        logging.info(f"íŒ¨í„´ ë¶„ì„ ì™„ë£Œ: {len(self.real_questions)}ê°œ ì§ˆë¬¸")
    
    def _analyze_style_patterns(self, question: str):
        """ë¬¸ì²´ íŒ¨í„´ ë¶„ì„"""
        # ì¡´ëŒ“ë§/ë°˜ë§ íŒ¨í„´
        if re.search(r'[ìš”|ë‹ˆë‹¤|ìŠµë‹ˆë‹¤|ë‹ˆë‹¤]', question):
            self.style_patterns['formal'].append(question)
        elif re.search(r'[ì•¼|ì–´|ì•„|ì§€]', question):
            self.style_patterns['informal'].append(question)
        else:
            self.style_patterns['mixed'].append(question)
        
        # ì´ëª¨ì§€ ì‚¬ìš© íŒ¨í„´
        if re.search(r'[ğŸ˜€-ğŸ™ğŸŒ€-ğŸ—¿]', question):
            self.style_patterns['emoji'].append(question)
        
        # ë§ì¤„ì„í‘œ íŒ¨í„´
        if re.search(r'\.{2,}', question):
            self.style_patterns['ellipsis'].append(question)
        
        # ê°íƒ„ì‚¬ íŒ¨í„´
        if re.search(r'[ì•„|ì–´|ì˜¤|ìš°|ìœ¼|ì´]+\!+', question):
            self.style_patterns['exclamation'].append(question)
        
        # ë¶ˆí™•ì‹¤í•¨ í‘œí˜„ íŒ¨í„´
        if re.search(r'[ê°™ì€ë°|ê°™ì€|ê²ƒ ê°™ì€|ëª¨ë¥´ê² ì–´|ì˜ ëª¨ë¥´ê² ì–´]', question):
            self.style_patterns['uncertain'].append(question)
        
        # ê¸´ê¸‰í•¨ í‘œí˜„ íŒ¨í„´
        if re.search(r'[ê¸‰í•´|ë¹¨ë¦¬|ì‹œí—˜|ë‚´ì¼|ì˜¤ëŠ˜]', question):
            self.style_patterns['urgent'].append(question)
    
    def _extract_topic_keywords(self, question: str):
        """ì£¼ì œë³„ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ìˆ˜í•™ ì£¼ì œë³„ í‚¤ì›Œë“œ
        math_topics = {
            'ìˆ˜ì—´': ['ìˆ˜ì—´', 'ë“±ì°¨ìˆ˜ì—´', 'ë“±ë¹„ìˆ˜ì—´', 'ì¼ë°˜í•­', 'ê³µì°¨', 'ê³µë¹„'],
            'ì í™”ì‹': ['ì í™”ì‹', 'ì¬ê·€', 'an+1', 'an-1'],
            'ê·€ë‚©ë²•': ['ê·€ë‚©ë²•', 'ìˆ˜í•™ì ê·€ë‚©ë²•', 'n=k', 'n=k+1'],
            'ìˆ˜ì—´ì˜í•©': ['í•©', 'ì‹œê·¸ë§ˆ', 'Î£', 'í•©ê³„'],
            'í•¨ìˆ˜': ['í•¨ìˆ˜', 'f(x)', 'ì •ì˜ì—­', 'ì¹˜ì—­'],
            'ë¯¸ë¶„': ['ë¯¸ë¶„', 'ë„í•¨ìˆ˜', 'f\'(x)', 'ì ‘ì„ '],
            'ì ë¶„': ['ì ë¶„', 'ë¶€ì •ì ë¶„', 'ì •ì ë¶„', 'âˆ«'],
            'í™•ë¥ ': ['í™•ë¥ ', 'ì¡°í•©', 'ìˆœì—´', 'ê²½ìš°ì˜ìˆ˜'],
            'í†µê³„': ['í‰ê· ', 'ë¶„ì‚°', 'í‘œì¤€í¸ì°¨', 'ì •ê·œë¶„í¬']
        }
        
        for topic, keywords in math_topics.items():
            for keyword in keywords:
                if keyword in question:
                    self.topic_keywords[topic].append(question)
                    break
    
    def _categorize_question_patterns(self, question: str):
        """ì§ˆë¬¸ íŒ¨í„´ ë¶„ë¥˜"""
        # ì§ˆë¬¸ ì‹œì‘ íŒ¨í„´
        if re.match(r'^[ê°€-í£]*[ê°€-í£]+\?', question):
            self.question_patterns['direct_question'].append(question)
        elif re.match(r'^[ê°€-í£]*[ê°€-í£]+[ê°€-í£]*[ê°€-í£]+\?', question):
            self.question_patterns['detailed_question'].append(question)
        
        # ì„¤ëª… ìš”ì²­ íŒ¨í„´
        if re.search(r'[ì„¤ëª…|ì•Œë ¤ì¤˜|ê°€ë¥´ì³|ë„ì™€ì¤˜]', question):
            self.question_patterns['explanation_request'].append(question)
        
        # í™•ì¸ ìš”ì²­ íŒ¨í„´
        if re.search(r'[ë§ë‚˜|ë§ëŠ”ì§€|í‹€ë ¸ë‚˜|ì–´ë–»ê²Œ]', question):
            self.question_patterns['verification_request'].append(question)
        
        # ì˜ˆì‹œ ìš”ì²­ íŒ¨í„´
        if re.search(r'[ì˜ˆì‹œ|ì˜ˆì œ|ë¬¸ì œ|í’€ì´]', question):
            self.question_patterns['example_request'].append(question)
    
    def generate_deepfake_question(self, 
                                 target_topic: str, 
                                 style_preference: str = None,
                                 difficulty: str = 'intermediate') -> str:
        """ë”¥í˜ì´í¬ì‹ ì§ˆë¬¸ ìƒì„±"""
        if not self.real_questions:
            return "ê¸°ë³¸ ì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ìŠ¤íƒ€ì¼ ì„ íƒ
        if style_preference and style_preference in self.style_patterns:
            available_styles = self.style_patterns[style_preference]
        else:
            available_styles = self.real_questions
        
        if not available_styles:
            available_styles = self.real_questions
        
        # í…œí”Œë¦¿ ì§ˆë¬¸ ì„ íƒ
        template_question = random.choice(available_styles)
        
        # ì£¼ì œë³„ í‚¤ì›Œë“œ ë§¤í•‘
        topic_mapping = self._get_topic_mapping(target_topic)
        
        # ë”¥í˜ì´í¬ ì§ˆë¬¸ ìƒì„±
        deepfake_question = self._apply_topic_transformation(template_question, topic_mapping)
        
        # ë‚œì´ë„ì— ë”°ë¥¸ ì¡°ì •
        deepfake_question = self._adjust_difficulty(deepfake_question, difficulty)
        
        return deepfake_question
    
    def _get_topic_mapping(self, target_topic: str) -> Dict[str, str]:
        """ì£¼ì œë³„ í‚¤ì›Œë“œ ë§¤í•‘"""
        topic_mappings = {
            'ìˆ˜ì—´': {
                'ìˆ˜ì—´': 'ìˆ˜ì—´',
                'ë“±ì°¨ìˆ˜ì—´': 'ë“±ì°¨ìˆ˜ì—´',
                'ë“±ë¹„ìˆ˜ì—´': 'ë“±ë¹„ìˆ˜ì—´',
                'ì¼ë°˜í•­': 'ì¼ë°˜í•­',
                'ê³µì°¨': 'ê³µì°¨',
                'ê³µë¹„': 'ê³µë¹„',
                'ì í™”ì‹': 'ì í™”ì‹',
                'ì¬ê·€': 'ì¬ê·€'
            },
            'ì í™”ì‹': {
                'ìˆ˜ì—´': 'ì í™”ì‹',
                'ë“±ì°¨ìˆ˜ì—´': 'ì„ í˜•ì í™”ì‹',
                'ë“±ë¹„ìˆ˜ì—´': 'ì§€ìˆ˜ì í™”ì‹',
                'ì¼ë°˜í•­': 'ì¼ë°˜í•­',
                'ê³µì°¨': 'ê³„ìˆ˜',
                'ê³µë¹„': 'ê³„ìˆ˜',
                'ì í™”ì‹': 'ì í™”ì‹',
                'ì¬ê·€': 'ì¬ê·€'
            },
            'ê·€ë‚©ë²•': {
                'ìˆ˜ì—´': 'ê·€ë‚©ë²•',
                'ë“±ì°¨ìˆ˜ì—´': 'ìˆ˜í•™ì ê·€ë‚©ë²•',
                'ë“±ë¹„ìˆ˜ì—´': 'ìˆ˜í•™ì ê·€ë‚©ë²•',
                'ì¼ë°˜í•­': 'ì„±ì§ˆ',
                'ê³µì°¨': 'ì¡°ê±´',
                'ê³µë¹„': 'ì¡°ê±´',
                'ì í™”ì‹': 'ê·€ë‚©ê°€ì •',
                'ì¬ê·€': 'ê·€ë‚©ë‹¨ê³„'
            },
            'ìˆ˜ì—´ì˜í•©': {
                'ìˆ˜ì—´': 'ìˆ˜ì—´ì˜í•©',
                'ë“±ì°¨ìˆ˜ì—´': 'ë“±ì°¨ìˆ˜ì—´ì˜í•©',
                'ë“±ë¹„ìˆ˜ì—´': 'ë“±ë¹„ìˆ˜ì—´ì˜í•©',
                'ì¼ë°˜í•­': 'í•©ê³„',
                'ê³µì°¨': 'í•­ì˜ê°œìˆ˜',
                'ê³µë¹„': 'í•­ì˜ê°œìˆ˜',
                'ì í™”ì‹': 'í•©ì˜ì í™”ì‹',
                'ì¬ê·€': 'ëˆ„ì í•©'
            }
        }
        
        return topic_mappings.get(target_topic, {})
    
    def _apply_topic_transformation(self, template: str, mapping: Dict[str, str]) -> str:
        """í…œí”Œë¦¿ì— ì£¼ì œ ë³€í™˜ ì ìš©"""
        result = template
        
        # í‚¤ì›Œë“œ ì¹˜í™˜
        for old_keyword, new_keyword in mapping.items():
            if old_keyword in result:
                result = result.replace(old_keyword, new_keyword)
        
        # ì¶”ê°€ì ì¸ ì£¼ì œë³„ ë³€í™˜
        if 'ìˆ˜ì—´' in result and 'ìˆ˜ì—´' not in result:
            result = result.replace('ìˆ˜ì—´', 'ìˆ˜ì—´')
        if 'ì í™”ì‹' in result and 'ì í™”ì‹' not in result:
            result = result.replace('ì í™”ì‹', 'ì í™”ì‹')
        if 'ê·€ë‚©ë²•' in result and 'ê·€ë‚©ë²•' not in result:
            result = result.replace('ê·€ë‚©ë²•', 'ê·€ë‚©ë²•')
        
        return result
    
    def _adjust_difficulty(self, question: str, difficulty: str) -> str:
        """ë‚œì´ë„ì— ë”°ë¥¸ ì§ˆë¬¸ ì¡°ì •"""
        if difficulty == 'naive':
            # ê¸°ë³¸ ê°œë… ìˆ˜ì¤€
            if 'ì–´ë–»ê²Œ' in question:
                question = question.replace('ì–´ë–»ê²Œ', 'ê°„ë‹¨í•˜ê²Œ ì–´ë–»ê²Œ')
            if 'ì„¤ëª…' in question:
                question = question.replace('ì„¤ëª…', 'ê¸°ë³¸ ì„¤ëª…')
        
        elif difficulty == 'basic':
            # ê¸°ì´ˆ ìˆ˜ì¤€
            pass
        
        elif difficulty == 'intermediate':
            # ì¤‘ê¸‰ ìˆ˜ì¤€
            if 'ì–´ë–»ê²Œ' in question:
                question = question.replace('ì–´ë–»ê²Œ', 'êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–»ê²Œ')
        
        elif difficulty == 'advanced':
            # ê³ ê¸‰ ìˆ˜ì¤€
            if 'ì–´ë–»ê²Œ' in question:
                question = question.replace('ì–´ë–»ê²Œ', 'ì •í™•í•˜ê²Œ ì–´ë–»ê²Œ')
            if 'ì„¤ëª…' in question:
                question = question.replace('ì„¤ëª…', 'ìì„¸í•œ ì„¤ëª…')
        
        elif difficulty == 'olympiad':
            # ì˜¬ë¦¼í”¼ì•„ë“œ ìˆ˜ì¤€
            if 'ì–´ë–»ê²Œ' in question:
                question = question.replace('ì–´ë–»ê²Œ', 'ì—„ë°€í•˜ê²Œ ì–´ë–»ê²Œ')
            if 'ì„¤ëª…' in question:
                question = question.replace('ì„¤ëª…', 'ì—„ë°€í•œ ì¦ëª…')
        
        return question
    
    def generate_multiple_questions(self, 
                                  target_topic: str, 
                                  count: int = 5,
                                  style_variety: bool = True) -> List[str]:
        """ì—¬ëŸ¬ ê°œì˜ ë”¥í˜ì´í¬ ì§ˆë¬¸ ìƒì„±"""
        questions = []
        
        for i in range(count):
            if style_variety:
                # ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ë¡œ ìƒì„±
                available_styles = list(self.style_patterns.keys())
                style = random.choice(available_styles)
            else:
                style = None
            
            question = self.generate_deepfake_question(target_topic, style)
            questions.append(question)
        
        return questions
    
    def analyze_question_style(self, question: str) -> Dict[str, any]:
        """ì§ˆë¬¸ì˜ ìŠ¤íƒ€ì¼ ë¶„ì„"""
        analysis = {
            'formality': 'mixed',
            'has_emoji': False,
            'has_ellipsis': False,
            'has_exclamation': False,
            'uncertainty_level': 0,
            'urgency_level': 0,
            'pattern_type': 'unknown'
        }
        
        # ì¡´ëŒ“ë§/ë°˜ë§ ë¶„ì„
        formal_count = len(re.findall(r'[ìš”|ë‹ˆë‹¤|ìŠµë‹ˆë‹¤|ë‹ˆë‹¤]', question))
        informal_count = len(re.findall(r'[ì•¼|ì–´|ì•„|ì§€]', question))
        
        if formal_count > informal_count:
            analysis['formality'] = 'formal'
        elif informal_count > formal_count:
            analysis['formality'] = 'informal'
        
        # ì´ëª¨ì§€ ë¶„ì„
        analysis['has_emoji'] = bool(re.search(r'[ğŸ˜€-ğŸ™ğŸŒ€-ğŸ—¿]', question))
        
        # ë§ì¤„ì„í‘œ ë¶„ì„
        analysis['has_ellipsis'] = bool(re.search(r'\.{2,}', question))
        
        # ê°íƒ„ì‚¬ ë¶„ì„
        analysis['has_exclamation'] = bool(re.search(r'[ì•„|ì–´|ì˜¤|ìš°|ìœ¼|ì´]+\!+', question))
        
        # ë¶ˆí™•ì‹¤í•¨ ìˆ˜ì¤€
        uncertainty_words = ['ê°™ì€ë°', 'ê°™ì€', 'ê²ƒ ê°™ì€', 'ëª¨ë¥´ê² ì–´', 'ì˜ ëª¨ë¥´ê² ì–´', 'ì•„ë§ˆ', 'í˜¹ì‹œ']
        analysis['uncertainty_level'] = sum(1 for word in uncertainty_words if word in question)
        
        # ê¸´ê¸‰í•¨ ìˆ˜ì¤€
        urgency_words = ['ê¸‰í•´', 'ë¹¨ë¦¬', 'ì‹œí—˜', 'ë‚´ì¼', 'ì˜¤ëŠ˜', 'ë‹¹ì¥', 'ë°”ë¡œ']
        analysis['urgency_level'] = sum(1 for word in urgency_words if word in question)
        
        # íŒ¨í„´ íƒ€ì… ë¶„ì„
        for pattern_type, questions in self.question_patterns.items():
            if question in questions:
                analysis['pattern_type'] = pattern_type
                break
        
        return analysis
    
    def get_style_statistics(self) -> Dict[str, int]:
        """ìŠ¤íƒ€ì¼ë³„ í†µê³„"""
        stats = {}
        for style, questions in self.style_patterns.items():
            stats[style] = len(questions)
        return stats
    
    def get_topic_statistics(self) -> Dict[str, int]:
        """ì£¼ì œë³„ í†µê³„"""
        stats = {}
        for topic, questions in self.topic_keywords.items():
            stats[topic] = len(questions)
        return stats

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ­ ë”¥í˜ì´í¬ì‹ í•™ìƒ ì§ˆë¬¸ ìƒì„±ê¸° ì‹œì‘\n")
    
    # í™˜ê²½ ì„¤ì • í™•ì¸
    print("ğŸ”§ í™˜ê²½ ì„¤ì • í™•ì¸:")
    data_path = os.getenv('DATA_PATH', 'data/evaluation_statistics.json')
    log_level = os.getenv('LOG_LEVEL', 'INFO')
    max_questions = os.getenv('MAX_QUESTIONS', '1000')
    
    print(f"  ë°ì´í„° ê²½ë¡œ: {data_path}")
    print(f"  ë¡œê·¸ ë ˆë²¨: {log_level}")
    print(f"  ìµœëŒ€ ì§ˆë¬¸ ìˆ˜: {max_questions}")
    print()
    
    # ìƒì„±ê¸° ì´ˆê¸°í™”
    generator = DeepfakeQuestionGenerator(data_path)
    
    if not generator.real_questions:
        print("âŒ ì‹¤ì œ ì§ˆë¬¸ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… {len(generator.real_questions)}ê°œì˜ ì‹¤ì œ ì§ˆë¬¸ ë¡œë“œ ì™„ë£Œ\n")
    
    # ìŠ¤íƒ€ì¼ í†µê³„ ì¶œë ¥
    style_stats = generator.get_style_statistics()
    print("ğŸ“Š ìŠ¤íƒ€ì¼ë³„ í†µê³„:")
    for style, count in style_stats.items():
        print(f"  {style}: {count}ê°œ")
    
    print()
    
    # ì£¼ì œë³„ í†µê³„ ì¶œë ¥
    topic_stats = generator.get_topic_statistics()
    print("ğŸ“š ì£¼ì œë³„ í†µê³„:")
    for topic, count in topic_stats.items():
        print(f"  {topic}: {count}ê°œ")
    
    print("\n" + "="*60 + "\n")
    
    # ë‹¤ì–‘í•œ ì£¼ì œë¡œ ë”¥í˜ì´í¬ ì§ˆë¬¸ ìƒì„±
    topics = ['ìˆ˜ì—´', 'ì í™”ì‹', 'ê·€ë‚©ë²•', 'ìˆ˜ì—´ì˜í•©']
    
    for topic in topics:
        print(f"ğŸ¯ ì£¼ì œ: {topic}")
        print("-" * 40)
        
        # ë‹¤ì–‘í•œ ë‚œì´ë„ë¡œ ì§ˆë¬¸ ìƒì„±
        difficulties = ['naive', 'basic', 'intermediate', 'advanced', 'olympiad']
        
        for difficulty in difficulties:
            question = generator.generate_deepfake_question(topic, difficulty=difficulty)
            print(f"{difficulty:12}: {question}")
        
        print()
    
    print("="*60 + "\n")
    
    # ìŠ¤íƒ€ì¼ë³„ ì§ˆë¬¸ ìƒì„± ì˜ˆì‹œ
    print("ğŸ­ ìŠ¤íƒ€ì¼ë³„ ì§ˆë¬¸ ìƒì„± ì˜ˆì‹œ:")
    print("-" * 40)
    
    styles = ['formal', 'informal', 'emoji', 'ellipsis', 'uncertain', 'urgent']
    
    for style in styles:
        if style in generator.style_patterns and generator.style_patterns[style]:
            question = generator.generate_deepfake_question('ìˆ˜ì—´', style)
            print(f"{style:10}: {question}")
    
    print("\n" + "="*60 + "\n")
    
    # ì—¬ëŸ¬ ì§ˆë¬¸ í•œë²ˆì— ìƒì„±
    print("ğŸ”„ ì—¬ëŸ¬ ì§ˆë¬¸ í•œë²ˆì— ìƒì„±:")
    print("-" * 40)
    
    multiple_questions = generator.generate_multiple_questions('ì í™”ì‹', count=3, style_variety=True)
    
    for i, question in enumerate(multiple_questions, 1):
        print(f"{i}. {question}")
    
    print("\nâœ… ë”¥í˜ì´í¬ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ!")

if __name__ == "__main__":
    main()
